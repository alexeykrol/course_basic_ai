# 2. Для каких случаев какую модель применять? Сравнение — популярных моделей ИИ и их режимов.

#### Оглавление

1. [Что будет в этом дополнении?](#что-будет-в-этом-дополнении)
2. [Видео](#видео)
3. [Расшифровка видео со всеми темами (нажмите треугольник слева, чтобы раскрыть)](#расшифровка-видео-со-всеми-темами-нажмите-треугольник-слева-чтобы-раскрыть)

## Что будет в этом дополнении?

1. Разберёмся, **какие ИИ-модели вообще бывают**, и когда использовать GPT, Gemini, Claude, Perplexity, Grok и другие.
2. Поймём, **какие задачи бывают у пользователей ИИ**, и какие модели лучше подходят под разные типы задач — от рецептов до программирования.
3. Посмотрим, **чем отличаются бесплатные и платные версии**, и почему платные всё же сильно выигрывают по возможностям.
4. Обсудим, **что такое «глубокое исследование» (Deep Search)** и зачем оно нужно — особенно в юридике, медицине, науке и аналитике.
5. Поговорим о **контекстном окне**: что это, зачем важно, и сколько текста могут «удержать в памяти» разные модели.
6. Проведём **сравнение моделей по умности, скорости, цене и возможностям**, включая свежие версии вроде GPT-4.1.
7. Узнаем, **как подключать ИИ через API**, сколько это стоит, и как не вылететь в трубу по бюджету.
8. Посмотрим, **какие есть удобные инструменты и платформы** для автоматизации с ИИ — Make, Zapier, n8n и другие.
9. Объясним, **как использовать модели для решения более сложных задач**, вроде кода, отладки и логического анализа.
10. И, наконец, разложим всё по полочкам: **что выбрать и зачем**, чтобы не ломать голову и использовать ИИ эффективно и по делу.

## Видео

## Расшифровка видео со всеми темами (нажмите треугольник слева, чтобы раскрыть)

Всем привет! Часто возникает вопрос: как применять разные модели? Вот здесь много моделей — в каких случаях и какие модели использовать? Потому что их реально много.

Из основных моделей у нас есть ChatGPT, Google Gemini, Anthropic Claude, Grok, Perplexity, DeepSeek, Qwen — вот здесь я даже голос ломать не буду. Немного порассуждаю на эту тему.

Во-первых, какие из популярных моделей вообще есть? В целом, если вам мало представленных моделей, можно зайти на HuggingFace — здесь почти миллион, 740 тысяч с лишним моделей. Причём многие из них специализированные. Их можно прямо там запускать и экспериментировать сколько угодно.

Но если взять подавляющее большинство публики, условно 99% всех людей, которые пользуются искусственным интеллектом, то основная масса запросов — это «дай мне рецепт горохового супа». И для этих целей, для 99% пользователей, какой-нибудь ChatGPT 4.0 — это best choice. Голову себе ломать сильно не надо. Тут я говорю только о платных тарифах, потому что они дают минимально нормальный уровень возможностей. Про бесплатные — играйте сами.

Если, допустим, вы предпочитаете Google Gemini, то там есть тариф 2.5 Pro — вот видите, написано: «Быстрая помощь с любыми задачами». Это примерно аналог GPT-4.0. Соответственно, если идёте в Grok, там два формата: один — когда заходите из-под Twitter, особенно если у вас платный аккаунт — он автоматически даёт доступ к Grok. Вот, видите, третья моделька. Либо есть вариант с сайтом.

Если хотите делать упор на фактический материал — потому что многие модели обвиняют в галлюцинациях — тогда обычно используют Perplexity. Он заточен не просто под ответ, а именно с подтверждением, с ссылками, по крайней мере — откуда он это взял. Мы все понимаем, что если он входит в какой-то сайт, то вопросы к сайту, а не к Perplexity. Насколько я знаю, до определённого времени они в основном использовали внешние модели — типа PaLM или Claude. Вроде бы у них сейчас появились свои, но я в Perplexity глубоко не лез, потому что если нужны ссылки и подтверждения, есть режим DeepSearch — он есть во всех этих сервисах.

Для русскоговорящей публики, особенно под санкциями, популярен DeepSeek — потому что для него не нужен VPN. Иногда люди используют модельку Qwen — китайского производства, тоже вроде без VPN.

Ну а если кому-то мало, кто хочет сильно упороться — идите на HuggingFace и ищите. Там миллион с лишним моделей и так далее.

Теперь собственно: внутри этих моделей они все примерно одинаковые. Есть куча бенчмарков, или лучше сказать — соревнований, и в целом они показывают примерно одинаковые результаты. Но специфика отличается — в зависимости от того, какие задачи вы ставите.

Все задачи можно условно разделить на два… точнее, три типа. Первая — это простые вопросы, например, рецепт горохового супа. То есть обычный режим «бла-бла-бла» диалога. Вот для таких задач — GPT-4.0 без проблем.

Если вы уходите в Gemini — тут тоже, видите, «быстрая помощь с любыми задачами» — просто бла-бла-бла. Они даже кулинарные тренды выделили — потому что подавляющее большинство запросов — про это.

Есть масса интересной статистики: молодое поколение — до 25 лет, либо такие отморозки, как я — используют AI по полной программе. Люди среднего возраста (35–45) — в основном как советчика. А постарше — как замену Google-поиску. Потому что AI не просто находит что-то, но и объясняет.

Claude я использую крайне редко. В целом, его доля ничтожна по сравнению с GPT. Чтобы вы понимали, если мы нажмём вот сюда, где можно посмотреть трафик, — вы увидите, что у GPT больше 5 миллиардов посещений в месяц. Он сейчас занимает 6-е место в глобальном рейтинге. Иногда его опережает Twitter.

Вот если нажать сюда — видно: Google, YouTube, Facebook, Instagram — а GPT уже обошёл Twitter и сейчас на 5-м месте в мире. Я думаю, через какое-то время он обгонит всех. Учитывая, что буквально месяц назад доля Google в поиске, которая с 2016 года не менялась (90%), впервые начала снижаться. Причина — огромное количество людей предпочитает использовать AI вместо Google, потому что это удобнее. Он сразу даёт какой-то результат.

Это что касается общих вопросов. Если хотите что-то с фактической ссылкой, глубоким исследованием — практически у всех моделей есть специальный режим. Например, если нажать кнопку «Инструменты», — видите, тут есть: «Проведите глубокое исследование». Это всё равно что вы наняли аналитика, который получает от вас техническое задание на исследование, а затем ищет источники, собирает, консолидирует и так далее. Это крутая опция — по сути, она обнулила работу маркетинговых и исследовательских агентств.

Похожие опции есть почти везде. Если зайдёте в Google Gemini — там внизу тоже есть DeepResearch. То есть модель та же самая, просто включается другой режим.

В Клауде он вообще как-то странно работает. Вот, допустим, когда я начал этот ролик записывать — он просто висел с моей точки зрения. А вот сейчас отвис. У него есть режим «Проект», я его не тестил, потому что традиционно всё делаю через чат.

Был у него режим «Спейс», куда можно было консолидировать какие-то отчёты, документы. Был в том числе режим «Гипспейс», потом они это всё куда-то отменили, и у меня всё это просто пропало. Что, мягко говоря, не добавило доверия к этому, кхм, «факин Клауду».

Напоминаю: если мы смотрим на этот замечательный сервис (ChatGPT), то у него трафик — больше 5 миллиардов посещений в месяц. То есть это пятый сайт в мире по посещениям.

А вот программисты и разработчики обычно «фапают» на Клауд, считая, что он супер в коде — что, на самом деле, неправда. Чтобы понимать реальную позицию Клауда от Anthropic — у него всего 96 миллионов посещений в месяц. Сравните: 5 миллиардов и 96 миллионов — он где-то на 490-м месте в мире. В основном пользуются США и Индия. Тут ещё вроде Бразилия, Аргентина — сложно сказать точно.

Давайте теперь посмотрим на Gemini. У них всё хитро: они скрывают трафик, потому что работают под доменом Google. Поэтому оценка охвата не совсем актуальна.

Теперь смотрим Grok. У Grok тоже есть режим DeepSearch, есть режим Think — типа «поразмышляй». Мы об этом чуть позже поговорим. Есть два варианта доступа: либо через Twitter, либо напрямую через их сайт. Вот, на сайте — та же история: режим DeepSearch, режим Think. Причём два формата — один, видимо, попроще, второй — типа он больше рассуждает. То есть: здесь он рассуждает, а там он больше рассуждает. Не такой тупой, замечательно.

Теперь по охвату. У Grok меньше 200 миллионов. Он только-только начал расти — с февраля, когда вышел третий Grok, Маск его активно прокачивает. Понятно, что если бы у Маска не было Twitter — этот Grok никто бы не заметил. География та же: в основном США, Индия. В Индии, кстати, пользуются больше.

Дальше смотрим Perplexity — популярный ресурс для поиска. У него 113 миллионов посещений. Неплохо, но по сравнению с 5 миллиардами — сами понимаете. Он на 379-м месте в мире. Двигается медленно, но стабильно, потому что его часто используют именно для поиска. Видите — здесь уже появился DeepSearch. Они делают какие-то свои проекты, развивают сервис.

Perplexity — в принципе, законодатели моды в своей нише. Их доля рынка — процентов 85. Все остальные постоянно у них воруют, пытаются догнать и копировать.

Теперь DeepSeek. У него тоже есть некий DeepThink — режим рассуждений. И тот же самый Search. Хотя я не уверен, что это DeepSearch, потому что Search — это просто возможность выходить в интернет. Например, в Клауде эту опцию раскатали буквально недавно. Сейчас глянем. Да, вот — WebSearch появился буквально день назад. До этого искать он вообще ничего не мог.

Теперь Qwen. Я с ним лично не работаю, но в целом — всё то же самое. Тот же Search. Если приглядеться — они фактически близнецы. Всё друг у друга воруют.

Так что в отношении моделей — всё достаточно просто. Когда у вас возникает выбор, моя личная рекомендация: голос не ломайте — в 99% случаев вы будете вполне удовлетворены ChatGPT 4.0. Он на доллар дороже, чем Google Gemini, но это уже абсурд — исключительно символическая разница.

Если вы чуть более продвинутый пользователь, и используете всё это через программные интерфейсы — то почти все модели дают стандартный API-доступ. Например, заходите на OpenAI, у вас там дашборд, список ваших API-ключей, IP и так далее — всё как положено.

У OpenAI самая проработанная инфраструктура. Есть Playground, есть документация. Самое полезное — это режим сравнения моделей. Заходите в доки, находите раздел сравнения моделей. Вот, слева — выбираете «сравнение моделей», читаете общее описание, нажимаете магическую кнопочку, вставляете модельки для сравнения — и вперёд.

Если большая часть из вас будет использовать 4.0 — вот она, ку-ку, — и, допустим, сравнивать её с какой-нибудь 3.5, например, то что мы здесь видим? Это, так сказать, уровень «умности», reasoning, способность к рассуждению — то есть та же умность.

Вот у нас GPT-1, GPT-3, GPT-4 — видите, есть разница в скорости, можно сравнивать цену токенов. Это особенно актуально, если вы используете API через программный интерфейс. Здесь куча-куча разных параметров — можно выставить любые модельки слева и справа и сравнивать.

У Google примерно то же самое. По-моему, у них это в разделе Media или Studio — переходите в Google AI Studio, и там уже побольше возможностей. Если вам нужно что-то построить, можно настраивать API и прочее-прочее. Пока я с ними плотно не работал, в основном обхожусь ChatGPT — мне хватает.

Если заходим в Claude от Anthropic — то же самое. Если хотите использовать его в более продвинутых сценариях, заходите в настройки. Хотя, если честно, Claude — самый убогий интерфейс, что я видел. Всё подтягивается медленно, нажимаешь — не работает. Вот раздел Billing, Integrations — ничего не отвечает. Ну, бог с ним. Потом покажу, где можно это всё использовать.

У Grok есть документация — DocX — всё как обычно: как получить API, как его подключать. Примерно то же самое, что у OpenAI. У Perplexity — всё по-простому: нажимаете на аккаунт, заходите в настройки — вот тут billing, вот API-ключи. Всё достаточно примитивно, но работает. У DeepSeek — тоже есть возможность использовать API. У Qwen — то же самое, всё идентично, не буду голос ломать.

Теперь важный момент: если у вас задача не просто найти что-то в интернете, а именно рассуждать, это уже третий тип задач.

Напомню:
1. Первый тип — это просто бла-бла на любые темы.
2. Второй — глубокое исследование (он лезет в интернет, собирает данные, делает аналитику, таблицы, ссылки и прочее).
3. Третий — серьёзные рассуждения, анализ, разработка, включая код.

Вот если вы работаете с кодом, допустим, пишете какие-то утилитки, вставляете потом в VSCode или в другую среду, и они выдают ошибку — вы даёте ChatGPT 4.0 сообщение об ошибке, просите: «Проанализируй, найди, исправь». В 90% случаев он не справляется.

А вот если ту же задачу дать O4-mini-high, или просто O4-mini, или даже O3 — они в 100% случаев находят ошибку и сразу исправляют. Прямо очевидная разница. Это был мой эксперимент, правда, полгода назад, но ощущение, что у этих моделей больше контекста. И это — важный момент.

Когда вы сравниваете модели — особенно при работе с большим объёмом данных — вот здесь у нас видно: «Context». У одной модели, допустим, 128K токенов, у другой — уже миллион. И выходное окно — до 32K. Это очень важно.

Сравниваем GPT-4.0 и GPT-4.1. Вот недавно раскатали 4.1 — вот она. Интеллект немного выше, скорость та же, входы-выходы те же, но при этом она подешевле, что немаловажно. И вот главное: у 4.0 контекст 128 тысяч токенов, у 4.1 — уже миллион. Выходное окно — 32K токенов. Это, чтобы вы понимали, уже другая лига.

Решил уточнить, сколько это в символах. Смотрим: миллион токенов — это примерно 4 миллиона символов (для английского), для русского — надо проверять. Я задал этот вопрос — вот, что мне ответили.

Чтобы проверить, копирую это, захожу в Gemini, задаю тот же вопрос. Смотрим, как ответит — считает, пыжится, показывает процесс размышления… ну, там вроде совпадает. Окей.

Теперь клауд. Проверим их на вшивость. Что они нам покажут?

А ну-ка, давай, Клауд, сделай что-нибудь.

Так. Сейчас нам в тему — вот этот стиль Extended Thinking. Ну-ка, может быть она там что-то выкатит. Давайте вот так вот сделаем, сейчас посмотрим, что даст. А ну давай, молодец, молодец, работает! Там пыль, пар — прямо из ушей! Так-так-так… ага, ну более-менее. Где-то миллион-другой туда-сюда, но идею вы поняли, да?

А теперь давайте, если уже совсем, так сказать, упороться — спросим у Grok. Что он нам тут даст? Видите, у них у всех очень сильно данные не совпадают. Но в сухом остатке, для простоты понимания, — для всех 99% людей, которые в основном туда заходят «за рецептами» — контекстное окно в миллион токенов это до хрена.

Даже при самом плохом раскладе — это два-три миллиона символов. Кто из вас хоть что-то пишет, понимает, насколько это чудовищно много. Просто чтобы вы понимали: средний художественный роман — это примерно полмиллиона символов. Понимаете, да? А это контекстное окно тянет — при самом плохом раскладе — два-три миллиона символов. То есть по объёму это три-четыре полноценных романа. Две «Войны и мир», грубо говоря.

Я думаю, для 99.9% людей на планете это в тысячу раз больше, чем им нужно вообще за всю жизнь, учитывая, что люди уже перестают учиться писать.

Соответственно, у вас есть несколько сценариев. Чтобы у вас в голове отложилось:

 Для простых, повседневных задач, в 99% случаев — используйте GPT-4.0 или аналогичные модельки. Без всяких дополнительных опций, без глубоких исследований. Просто отключите эти режимы, и этого будет с головой достаточно.

 Если вы хотите что-то с подтверждением, со ссылками, если для вас важна точность, особенно в юриспруденции, науке, медицине, технологиях, — где доверие к источнику критично, — тогда включаете режим типа «Проведите глубокое исследование». Это есть в GPT, в Perplexity, в Grok, где угодно. Просто включаете и используете.

 А если вы хотите совсем упороться, то можно включить режим расширенного анализа. Я сам не пробовал, но судя по описанию, он не просто собирает информацию, а как-то по-особенному анализирует — если правильно сформулировать задание. Это можно делать почти в любой модели, главное — правильно поставить задачу.

Важно: многие сервисы дают эти режимы только в платной подписке. Например, тот же Anthropic Claude — у них всё это в платном варианте. Но это стоит копейки — 19 долларов в месяц. Если вы супер-жадный, можно заплатить один раз, наисследоваться, а потом выключить. Всё.

Лично я плачу почти за всё. Сколько уходит на ИИ в месяц? Посчитал — ну, долларов 100–150, может, меньше. Всё зависит от сценариев, конечно.

Теперь — если вы используете программный интерфейс, то есть API, тогда надо понимать, что любая операция чарджится. Я вот провожу эксперименты, не сказать, что прям сильно много, — вот, смотрим: за последний месяц насчитали аж 4.5 доллара! Можно разориться, ха-ха.

Естественно, нужно к этому аккуратно подходить. Я, например, поставил себе лимит — вот тут: 30 долларов, и если сумма превышается, система просто останавливается. Это удобно — знаешь, что ничего не слетит, не разоришься, всё под контролем.

Кстати, многие из вас ходят в кафе, покупают кучу бесполезного… Так вот — лучше сюда заплатите, пользы будет больше.

Что ещё хотел показать… а, вот! В качестве среды разработки я привёл Make. Почему? Потому что программисты не умеют пользоваться no-code/low-code сервисами. Они по привычке всё делают кнопками, руками, «по старинке». Хотя, если вы дорожите временем — используйте low-code.

Самые популярные сейчас:
• Make — мы с ним работаем на курсе;
• Zapier — почти то же самое, но есть нюансы, интеграций чуть больше;
• n8n — тоже очень классный, разработчики его любят. Прикольный, гибкий, мощный.

Вот он — «зайчик», да. Ну и такой он, нормальный.

Начинать, для простоты, конечно, лучше с Make. Если у вас задачи посложнее — можно уже залезать в n8n, потому что у него побольше возможностей для комплексных сценариев. Но суть не в этом.

Вот, смотрите: я специально посмотрел — у вас уже есть интеграции. Есть интеграция с OpenAI, есть с Gemini, есть с Anthropic, с Perplexity, даже с DeepSeek. То есть вы всегда можете использовать это для того, чтобы делать какие-то небольшие автоматизации, выполнять конвейерные задачи и прочее.

Собственно, всё. Резюмирую ещё раз:

 Для простых и большинства задач — вам более чем достаточно общих моделей: GPT-4.0, Gemini, Claude и так далее.
 Хотите более глубокое исследование — включайте соответствующие инструменты. В GPT это «Проведите глубокое исследование».
 Хотите, чтобы модель искала в сети — включайте режим поиска (в некоторых это называется Web Search, в других — DeepSearch).
 Если нужна фактура, ссылки, доказательства — включайте именно этот режим. Это критично, если работаете с данными, юридическими или научными материалами.
 Если хотите, чтобы модель рассуждала, писала код, анализировала алгоритмы и решала нетривиальные задачи — тогда используете продвинутые модели. Например, GPT-4.1, O4-mini, O4-mini-high, O3 и так далее.

Если хотите лучше разобраться — заходите в режим сравнения моделей. Сравниваете, смотрите параметры, контексты, стоимость, производительность — и всё сразу становится понятно.


## Навигация по курсу

- [Предыдущий урок](<Урок 1. Какой ИИ лучше? Какой ИИ выбрать? От OpenAI, от Google, от Антропик, DeepSeek? Каким генератором .md>)
- [Содержание курса](README.md#карта-уроков)
- [Следующий урок](<Урок 3. Введение в chatGPT — Теория Каст и Ролей.md>)

# 5: Продвинутый промптинг. Как спрашивать, чтобы решать серьезные проблемы?

#### Оглавление

1. [Что будет в данном разделе?](#что-будет-в-данном-разделе)
2. [Кейсы, в которых обычные возможности плохо работают, а Deep Research спасает.](#кейсы-в-которых-обычные-возможности-плохо-работают-а-deep-research-спасает)
3. [Важный опрос. Всего один вопрос.](#важный-опрос-всего-один-вопрос)
4. [Видео](#видео)
5. [Расшифровка видео со всеми темами (нажмите треугольник слева, чтобы раскрыть)](#расшифровка-видео-со-всеми-темами-нажмите-треугольник-слева-чтобы-раскрыть)
6. [Пример исследования и отчета на выходе.](#пример-исследования-и-отчета-на-выходе)
7. [Самое важное! Как  я получил такой отчет?](#самое-важное-как-я-получил-такой-отчет)
8. [Пример системного промпта для Deep Research Promter.](#пример-системного-промпта-для-deep-research-promter)

   1. [Файл «Рекомендации для создания промптов для Deep Research от Open AI.md»](#файл-рекомендации-для-создания-промптов-для-deep-research-от-open-ai-md)
   2. [Файл «Образец ТЗ.md»](#файл-образец-тз-md)
   3. [Пример индексного файла index\_files.md](#пример-индексного-файла-index-files-md)
   4. [Пример файла аннотации lesson\_annotation.md](#пример-файла-аннотации-lesson-annotation-md)
   5. [Пример файла программы курса по созданию ИИ агентов final\_course\_program\_v1.0\_2025-03-11\_1430.md](#пример-файла-программы-курса-по-созданию-ии-агентов-final-course-program-v1-0-2025-03-11-1430-md)
   6. [Программа курса по ИИ агентам.](#программа-курса-по-ии-агентам)
   7. [Пример инструкции для настройки проекта?](#пример-инструкции-для-настройки-проекта)
9. [Пример структуры файлов для загрузки в проект?](#пример-структуры-файлов-для-загрузки-в-проект)
10. [Что в следующем уроке и почему это важно?](#что-в-следующем-уроке-и-почему-это-важно)

    1. [Сначала посмотрите на эти результаты опросов.](#сначала-посмотрите-на-эти-результаты-опросов)
    2. [И какой же вывод?](#и-какой-же-вывод)
    3. [Что из этого следует?](#что-из-этого-следует)
    4. [Вечный, пожизненный доступ](#вечный-пожизненный-доступ)

## Что будет в данном разделе?

****Поиск информации с помощью ИИ, исследование, отчеты и обзоры по исследованиям.** Использование режима Deep Reseacher для продвинутых исследований.**

Как создавать мощные промпты, чтобы Deep Reseacher писал вам целые диссертации? ИИ значительно упрощает сбор и анализ информации. Однако без понимания принципов поиска можно упустить важные детали или получить неточные данные.

Навыки работы с ИИ в исследованиях помогают формировать структурированные отчеты, находить ключевые выводы и избегать дезинформации. Это критично в науке, аналитике и стратегическом планировании.

**Продвинутый промптинг. Как спрашивать, чтобы решать серьезные проблемы?**

Промптинг – это ключ к эффективному взаимодействию с ИИ. Чем лучше сформулирован запрос, тем точнее и полезнее будет ответ. Промптинг особенно важен в критических ситуациях, например, при анализе данных для бизнеса, научных исследованиях или юридических вопросах. Умение задавать вопросы с учетом контекста, целей и ограничений значительно повышает результативность работы с ИИ.

**Работа с большими и сложными документами.**

ИИ может быстро обрабатывать большие объемы данных, но без структурированного подхода есть риск потери ключевой информации. Важно понимать, как лучше представлять данные для анализа, какие инструменты использовать и какие форматы предпочтительны. Это особенно актуально для юридических, финансовых и технических документов.

Правильный выбор форматов и структуры данных существенно влияет на качество анализа. Например, для текстовых документов предпочтительны форматы с четким структурированием (Markdown, JSON, CSV), а для изображений – высококачественные версии с мета-данными. Также важно понимать, как файлы связаны между собой, чтобы ИИ мог анализировать контекст.

**Создание много шаговых диалогов для опросов.**

Иногда очень полезно спросить клиентов или студентов, чтобы модель отвечала на основе ваших ответов.

## **Кейсы, в которых обычные возможности плохо работают, а Deep Research спасает.**

**1. Анализ конкурентоспособности рынка**

Мне нужно было понять, как мои конкуренты действуют, какие стратегии используют, на чем делают акцент. Я тратил часы, а иногда и дни, просматривая сайты, отчеты, отзывы и статьи, но каждый раз чувствовал, что что-то упускаю. **Без DR я потратил бы недели на сбор данных, а еще пришлось бы нанимать аналитика или покупать дорогие маркетинговые исследования за $2 000 – $5 000.** Когда я использовал **Deep Research**, система сама нашла актуальные данные, выявила скрытые тренды, и я сэкономил минимум 40 часов и тысячи долларов.

**2. Разработка маркетинговой стратегии**

Я пытался выстроить маркетинговую стратегию, изучал рынок, целевую аудиторию, смотрел успешные кейсы конкурентов. Но информация была разрозненной, данные устаревали, а тренды менялись слишком быстро. **Без DR мне бы пришлось платить маркетинговому агентству минимум $3 000, а работа затянулась бы на несколько недель.** С **Deep Research** я получил структурированный отчет с конкретными рекомендациями за несколько часов, сэкономив около 50 часов работы и тысячи долларов.

**3. Подготовка академического обзора литературы**

Когда я работал над научным обзором, мне приходилось вручную искать статьи, проверять их актуальность, разбираться в сложных терминах. **Обычно на это уходит от 2 до 4 недель, а иногда даже приходится платить за доступ к платным статьям, что стоит от $500 до $2 000.** С **Deep Research** он сам нашел самые свежие исследования, отсортировал их по значимости, убрал ненужное и даже сделал краткие выжимки. Я сэкономил минимум 80 часов работы и избежал расходов на доступ к научным базам.

**4. Исследование новых технологий**

Мне нужно было понять, какие технологии сейчас в тренде, какие стартапы могут стать революционными. **Без DR пришлось бы подписываться на дорогие аналитические платформы вроде CB Insights ($500+/мес) и тратить недели на изучение данных.** С **Deep Research** я получил не только обзор новейших разработок, но и прогнозы, что позволит мне быть впереди конкурентов. Экономия — минимум 60 часов работы и $1 000+ на аналитические отчеты.

**5. Оценка инвестиционных возможностей**

Я думал вложиться в несколько компаний, но сомневался. Финансовая аналитика казалась сложной, я боялся упустить важные нюансы. **Обычно для этого нанимают финансового консультанта ($200+/час) или покупают отчеты ($1 000+).** **Deep Research** сам собрал данные, проверил финансовые отчеты, выявил сильные и слабые стороны компаний. Я сэкономил около 40 часов анализа и как минимум $2 000 на услугах экспертов.

**6. Разработка политических рекомендаций**

Мне нужно было составить отчет о влиянии текущих политических решений на экономику, но информация была разбросана, а источники противоречили друг другу. **Раньше это занимало бы 2-3 недели и требовало привлечения аналитиков (от $3 000 за исследование).** **Deep Research** сам собрал актуальные данные, сравнил позиции разных экспертов, выявил тренды. В результате я сэкономил более 80 часов работы и несколько тысяч долларов.

**7. Анализ эффективности рекламных кампаний**

Я запускал рекламу, но не мог понять, какие каналы работают. **Без DR мне бы пришлось вручную анализировать данные из десятков отчетов, тратя на это минимум 30-50 часов, либо нанимать аналитика ($50+/час).** **Deep Research** автоматизировал этот процесс, выявил слабые места кампании и предложил стратегии оптимизации. Экономия — 40 часов и около $2 000.

**8. Исследование потребительских предпочтений**

Я пытался разобраться, чего хочет моя аудитория, анализировал отзывы, проводил опросы. **Без DR мне пришлось бы нанимать агентство ($5 000 – $10 000) или тратить месяцы на сбор данных.** **Deep Research** за короткое время обработал тысячи данных из соцсетей, форумов, исследований и выдал точный портрет потребителя. Итог: 100+ часов экономии и несколько тысяч долларов сохраненных средств.

**9. Разработка образовательных программ**

Я создавал курс, но не знал, как сделать его актуальным. **Раньше приходилось бы изучать программы конкурентов вручную (60+ часов) или заказывать исследования ($2 000 – $5 000).** **Deep Research** сам собрал информацию, выявил пробелы, предложил идеи. В результате я сэкономил недели работы и минимум $3 000.

**10. Оценка экологических рисков**

Мне нужно было понять, какие экологические угрозы могут повлиять на мой проект. **Обычно на это уходит несколько недель, а консалтинговые компании берут за такой анализ от $10 000.** **Deep Research** за несколько часов нашел ключевые риски, сделал прогноз и предложил стратегии их минимизации. Я сэкономил более 100 часов работы и десятки тысяч долларов.

**Вывод:**

Без **Deep Research** мне пришлось бы тратить недели на ручной поиск информации, привлекать экспертов, покупать дорогие отчеты. С **DR** я не только получил нужные данные в разы быстрее, но и обнаружил инсайты, о которых даже не думал. Экономия времени — **от 40 до 100 часов на каждую задачу**, а финансовая выгода — **от $2 000 до $10 000 в зависимости от сложности проекта**.

## Важный опрос. Всего один вопрос.

## Видео

## Расшифровка видео со всеми темами (нажмите треугольник слева, чтобы раскрыть)

Добрый день. Добрый день, добрый вечер.

У меня ушло три дня, чтобы сделать этот небольшой урок. Пришлось серьезно поработать, и сейчас вы поймете, почему.

Смотрите, на следующем курсе мы будем разбирать, как создавать агентов. Я уже рассказывал, что агенты отличаются от ассистентов тем, что могут выполнять сразу несколько задач в конвейере. Плюс они способны разбираться с реальностью, воспринимать неопределенные данные и так далее. Мы подробнее обсудим это на следующем курсе — я уже делал небольшой анонс.

Сейчас существует довольно много сервисов и подходов для создания таких агентов, и в целом ничего сложного в этом нет. В YouTube можно найти массу роликов о том, как делать агентов с помощью сервисов автоматизации, таких как **Make** или **Zapier** — это одни из самых популярных инструментов. Если вы начинаете с нуля, потребуется немного времени, чтобы разобраться, но сложного там ничего нет, программирование не требуется.

Однако, как обычно, важны детали. И вот сейчас вы поймете, зачем вообще этот урок.

Для начала я покажу вам пример одной достаточно типичной цепочки на YouTube, а затем объясню, в чем возникает проблема.

Так, секунду…

Ладно, еще раз объясню, к чему все это.

**Что такое агент?**

Чтобы было проще понять, о чем мы сегодня говорим и почему это важно, объясню на примере.

Представьте, что вам нужно сварить кофе. Этот процесс можно разделить на две части.

1. У вас есть **кофемолка**, в которую вы засыпаете зерна. Она перемалывает их, и на выходе получается молотый кофе.
2. Затем молотый кофе пересыпается в **кофеварку**, вы нажимаете кнопку, и кофе варится.

Теперь представьте, что в этой схеме кофемолка — это один исполнитель, кофеварка — другой исполнитель, и они «обмениваются» данными. В данном случае «данные» — это молотый кофе.

На вход кофемолки поступают зерна, на выходе — молотый кофе. Он загружается в кофеварку, а на выходе у нас что? Правильно, готовый кофе. Это и есть пример процесса.

Теперь заменим кофемолку и кофеварку на цифровых исполнителей: например, вместо молотого кофе будут данные, а вместо кофеварки и кофемолки — ассистент, такой, какого мы создаем. Если таких исполнителей несколько, они связаны между собой, обмениваются данными, выполняют разные задачи — это уже **агент**.

Сейчас существует множество роликов, показывающих, как можно создавать таких агентов. Вот, например, один из них.

(Жду, пока пройдет реклама…)

Вот видите, какой-то человек демонстрирует процесс в **Make**. Это популярная система автоматизации. У меня, например, там тоже много сценариев для бизнес-задач.

Система представляет собой схему из отдельных блоков — каждый блок выполняет узкую функцию. Из таких блоков можно собрать сложную систему.

То есть, если представить наш пример с кофе, один блок — это кофемолка, другой — кофеварка, а между ними передается молотый кофе. В **Make** таких блоков можно настроить сколько угодно.

Большинство подобных видео повторяют англоязычные материалы, но с переводом на русский. Американцы делают, русскоговорящие копируют.

**В чем проблема?**

В этих системах часто используется **ChatGPT**. На первый взгляд, осваивать их может быть непросто, но на самом деле сложность преувеличена. В интернете полно информации, разобраться можно бесплатно, главное — желание.

Но вот вы прошли все технические моменты, все настроили, все отлично работает… и тут сталкиваетесь с **главной проблемой**.

Вы организовали цепочку агентов, задали им задачи, например, обработку писем или данных, но вдруг обнаруживаете, что **они работают плохо**.

То есть вместо полезного результата вы получаете **абсурд**. Они не отвечают так, как вам нужно, качество информации оставляет желать лучшего — в общем, все выглядит глупо и бессмысленно.

Вы настроили автоматизацию, гордитесь проделанной работой, но сам по себе **технический процесс — это только инструмент**.

Наша главная цель — это **качество результата**.

Мы обсуждали на одном из прошлых занятий, что самое важное — это **какие данные получает искусственный интеллект**.

Если вы просто пишете в **ChatGPT** вопросы в обычном диалоге, то получаете обычные ответы. Если же хотите автоматизировать процесс, можно нанять специалистов, которые соберут вам сложные системы с кучей блоков, интеграций, API.

Но если в этих системах **не продумана логика взаимодействия**, если **ChatGPT получает некорректные или нечеткие данные**, то агент будет вести себя **как идиот**.

И вот с этим мы сегодня разберемся.

**Отредактированный текст:**

Соответственно, причина этого в том, о чем я уже говорил: **как бы вы ни настроили систему, если вы не используете качественные промпты, если не понимаете, как правильно взаимодействовать с искусственным интеллектом, то толку не будет**.

Более того, если на базовом уровне вы не умеете корректно ставить задачи, то при создании сложной системы с множеством искусственных интеллектов и ассистентов, которые взаимодействуют между собой, **количество ошибок будет только расти**. Они не будут друг друга компенсировать, а, наоборот, увеличат количество хаоса.

**О чем мы поговорим сегодня**

Сегодняшнее занятие посвящено **продвинутому промптингу**. Мы разберем **конкретные кейсы**, которые особенно важны.

Один из ключевых кейсов — это использование **ChatGPT** и подобных сервисов **для проведения серьезных исследований**. Речь не про научные работы, а про **глубокий поисковый анализ**.

Я приведу примеры.

Один из них — анализ конкурентоспособности рынка.

Допустим, мне нужно понять, как действуют мои конкуренты: какие стратегии используют, на что делают акцент. Раньше я тратил **часы, а иногда и дни**, изучая сайты, отчеты, отзывы, статьи. Но каждый раз возникало ощущение, что я **что-то упускаю**.

Когда я попробовал делать это с помощью **ChatGPT** и функции **Deep Research**, я понял, что **без нее потратил бы неделю** только на сбор данных. А еще, скорее всего, пришлось бы нанимать аналитика или покупать маркетинговые отчеты за **тысячи долларов**.

Используя **Deep Research**, система сама нашла **актуальные данные, выявила скрытые тренды**, и в итоге я **сэкономил минимум 40 часов и тысячи долларов**.

Внизу я привел другие примеры подобных кейсов, вы сможете их прочитать.

**Почему это важно?**

**Deep Research** — **мощнейший инструмент**, который буквально **пару недель назад** стал доступен для **тарифа Plus**. До этого он был только на **тарифе Pro** (за 200$ в месяц). На данный момент он **опережает аналогичные решения от Google и Claude**, а единственные альтернативы — это **очень дорогие специализированные инструменты**.

Но, как и везде, есть **проблема**.

Если вы используете **некачественный промпт**, то, даже имея **мощный инструмент**, вы получите **плохой результат**.

**Как создать правильный промпт**

Я привел конкретный пример: сначала я использовал **простой промпт**, но затем его **улучшил** и получил **глубокое исследование**. Вы можете просто посмотреть разницу в результатах.

Очевидно, что **качественный результат появился не сам по себе** — его обеспечил **продвинутый промпт**.

И главный вопрос для вас — **как преобразовать примитивный запрос в мощный промпт**, который позволит использовать инструмент **по максимуму**.

**Практика**

Сам инструмент **очень прост в использовании** — буквально **одна кнопка**.

Поэтому, когда будем говорить об этом разделе, **особо нечего показывать**. Я, конечно, продемонстрирую процесс, но **главное — прочитать материал**.

Сейчас расшарю экран.

Вот он.

Выбираем модель **GPT-4**.

Вот эта кнопка — **включает режим глубокого исследования**.

Дальше просто вводим запрос.

**Разница между простым и продвинутым промптом**

Давайте посмотрим мой **первоначальный запрос**.

(Показываю на экране.)

Он **реалистичный**, потому что я действительно искал сервисы для создания агентов, виртуальных менторов и т. д.

Но, так как я уже работал с этим инструментом, я **понимал**, что этот запрос **недостаточно хорош**. **С таким промптом я не получу сильного результата**.

Теперь покажу **правильный промпт**.

(Вывожу на экран.)

Как видите, он **намного мощнее**.

И именно этот запрос **дал нужный результат**.

Дальше я покажу **пошаговый процесс**, как преобразовать **простой, неэффективный промпт** в **сильный и качественный**.

**Итог**

**Вся идея в том, что я не ломал голову**.

Я просто **постепенно улучшал запрос**, ведя диалог с **ChatGPT**.

Вы сможете **прочитать весь процесс**, потому что **я привел полный диалог**. Так вам будет легче понять, **как правильно действовать**.

**Отредактированный текст:**

Фактически я **задавал правильные вопросы ChatGPT**, чтобы он помог мне **из слабого промпта сделать сильный**.

Когда у меня появился **сильный промпт**, я уже вставил его **в режим Deep Research**.

До этого, в **обычном режиме**, я просто задавал вопросы. **Вы можете прочитать этот процесс — там все четко объясняется**.

**Почему это важно?**

Прежде чем предлагать вам что-то изучить, **я всегда объясняю, зачем это нужно**.

Если у вас возникают **исследовательские задачи**, то **Deep Research — незаменимый инструмент**.

Я привел **около 10 кейсов**, которые показывают, **как люди формулируют задачи** и **почему обычные методы не работают**.

Обычные запросы в ChatGPT или даже **ручной поиск** требуют **огромного количества времени**.

Поэтому:

 **Сначала читайте** — разберитесь, как это работает.

 **Потом практикуйтесь** — используйте метод в своих задачах.

**Как практиковаться?**

 **В обычном режиме**: сначала берете свою “хотелку” и с помощью **ChatGPT** улучшаете ее формулировку.

 **В режиме Deep Research**: когда у вас **готов качественный промпт**, переходите в этот режим.

Но здесь есть **ограничение** по количеству использований.

Этот инструмент **не предназначен для частого использования с простыми запросами**.

Он **мощный**, и его работа может занять от **5 минут до часа**.

 Например, отчет, который я вам показываю, он **генерировался 10 минут** и содержит **36 000 знаков**.

 Бывают кейсы, когда система пишет **реальную диссертацию**.

Поэтому **используйте его разумно**.

Как только ваш **продвинутый промпт готов**, **вставляете его в систему**, нажимаете кнопку — и **ждете результат**.

**Примеры исследований**

Многие из вас сталкивались с проблемой, **как проводить серьезные исследования**.

Для этого мы **используем подобные инструменты**.

Сейчас я покажу **несколько примеров**.

 **Cloud (Anthropic)** — тоже делал исследования, но **менее качественные**.

 **Groq** — имеет аналогичный инструмент, но **он слабее**.

**Вот пример отчета, который я делал:**

(Показываю экран.)

 **Анализ конкурентов** — отчет с кучей ссылок, четкими выводами, примерами.

 **Другие исследования** — глубокий анализ с графиками, таблицами, источниками.

Но то, что **сделал Deep Research в OpenAI, в разы лучше**.

 **Если вы занимаетесь маркетингом, аналитикой, стратегическим планированием**, это **суперинструмент**.

**Теперь про продвинутый промптинг**

Если у вас **сложная задача**, вам нужен **продвинутый промпт**.

 **Главная проблема** — как превратить **слабый и неполный промпт** в **сильный с полным контекстом**.

Для этого я использую **два инструмента**:

 **Сам ChatGPT** — для улучшения промптов.

 **Anthropic Claude** — дает очень приличные результаты.

Сейчас покажу, **как я это делал**.

(Показываю экран.)

 Вот мой пост, где я **экспериментировал с созданием ИИ-геймдизайнера**.

 Я дал **примитивный промпт**: “Напиши браузерную игру в жанре ‘три в ряд’”.

 **Но это слишком слабый промпт**, и результат был посредственным.

Теперь **покажу, как он был преобразован в мощный промпт**.

(Открываю Anthropic.)

 **Вот интерфейс Anthropic Claude**.

 Здесь **все просто**, но он позволяет **грамотно дорабатывать промпты**.

Итог: **чем лучше ваш промпт, тем мощнее результат**.

 **Дальше покажу, как именно формулировать такие промпты, чтобы получать выдающиеся результаты.**

И вот я выбираю написать, сгенерировать промпт с помощью искусственного интеллекта.

Сейчас я пройду по всей цепочке, которую вам показывал, чтобы наглядно продемонстрировать, как это работает.

[Текст на экране]

Сначала посмотрим, как здесь всё устроено.

Я должен написать свою базовую идею промпта. Для примера возьму игровую тематику. Возможно, кто-то из вас не играет, но это не важно, потому что моя цель – показать, как из простого промпта можно получить что-то более серьёзное и проработанное. Таким образом, можно добиться лучшего результата.

Вот здесь у нас окошко, я копирую текст прямо отсюда. Теперь переведу его на английский язык, чтобы нейросеть лучше поняла запрос. Вставляю сюда.

Далее указываем, что этот промпт предназначен для моделей, способных рассуждать. Посмотрим, что получится.

Видите, сформировался достаточно подробный промпт с пояснениями и уточнениями. Теперь его можно проверить.

Здесь мы задаём системный промпт и вводим пользовательский запрос. Я вставил сюда сгенерированный промпт. Теперь нажимаем кнопку **Run** и смотрим, что будет происходить.

Вот модель имитирует диалог. Поясню ещё раз, вдруг кому-то не совсем понятно.

Моя задача – создать геймдизайнера. Вместо геймдизайнера можно взять любого специалиста – программиста, бухгалтера, маркетолога и т. д.

Геймдизайнер работает так: я – пользователь, у меня нет опыта в геймдизайне, но я хочу создать игру. Я обращаюсь к нему с просьбой: «Уважаемый геймдизайнер, сделай мне игру». Чтобы нейросеть справилась с этим, мне нужно создать системный промпт – подробно описать, что геймдизайнер делает и как он работает.

Теперь вернёмся назад. Как я получил этот сложный, продуманный промпт? Всё начиналось с самого простого: я вставил сюда буквально одну короткую фразу. То есть на входе у меня был элементарный промпт, без каких-либо сложных описаний.

Нажимаем **Generate**. Там нужно было поставить галочку, но не суть важно. Сейчас отменю, вернусь и попробую снова.

Ставлю галочку, снова запускаю. Вот он – мой простой промпт, который затем превращается в детализированный вариант, учитывающий нюансы, о которых я мог забыть.

Почему это важно? Потому что моя задача – создать не просто текстовый запрос, а своего рода «мозг» геймдизайнера. Если вместо геймдизайнера вы подставите другую профессию, логика останется той же.

Нажимаю **Continue**. Готово, промпт создан. Теперь самое интересное – проверка.

Нажимаю **Run**, и модель спрашивает: «Какую игру ты хочешь сделать?»

Давайте проверим. Ввожу, например, «Сделай мне браузерную игру 3 в ряд».

Модель сразу же приступает к созданию. Видите, фактически готовый код игры! Сейчас он закончит. Всё практически в реальном времени.

Готово. В первый раз результат был немного короче, но суть та же.

[ТИХИЙ СИГНАЛ]

Получился довольно большой файл. Сейчас я не буду запускать его, потому что в коде всегда могут быть нюансы. Но вот что важно – модель действительно создала игру.

Вот, например, игра «три в ряд». Думаю, все знают, как в неё играть. Вот так – чик, и всё готово. Очень медитативно.

Но моя цель была не показать, что нейросеть умеет писать код – это и так понятно. Главное – продемонстрировать разницу между простым и продвинутым промптом.

Например, давайте попробуем что-то из другой области.

Допустим, я хочу получить объяснение квантовой физики. Пишу: **«Напиши краткое объяснение квантовой физики»**.

Это довольно общий запрос, но я специально выбрал такой вариант.

Скопирую его.

Модель понимает русский, но лучше использовать английский и затем переводить.

Заново создаю промпт.

Вставляю текст. На первый взгляд, всё и так понятно. Интересно, что изменится после обработки.

Идея в том, что разные уровни детализации промпта дают разные результаты. Сейчас мы разбираем способ, который помогает получить более качественные ответы.

Посмотрим, что выйдет.

Вот, смотрите, насколько улучшился промпт.

Теперь модель уточняет задачу: **«Ваша цель – написать короткое объяснение квантовой физики для широкой аудитории. Обеспечьте ясное, доступное понимание фундаментальных концепций без сложных теоретических деталей»**.

Вот так можно из простого запроса сделать что-то более проработанное и получить лучший результат.

Видите, он начинает писать очень подробно, объясняет всю структуру и так далее. Можно задать количество слов, добавить деталей и многое другое. Он дополнил промпт множеством уточнений.

Давайте просто потестируем, что будет дальше. Я сам не знаю, поэтому мне интересно.

Нажимаем волшебную кнопку **Run**.

Теперь надо что-то ввести, ведь мы уже научили модель писать мощные объяснения по квантовой механике. Окей, попробуем.

Допустим, я хочу узнать про квантовую запутанность. Посмотрим, что получится.

Обратите внимание: он сразу пишет в формате Markdown. Я уже объяснял, что это такое. Модель не просто даёт ответ — она структурирует информацию.

Сейчас проведём эксперимент, и вы увидите разницу. Не переживайте, что ответ на английском. Я видел, что многие используют его и для русского, можем попробовать.

В принципе, то же самое можно делать в **ChatGPT**, но для некоторых задач этот инструмент удобнее.

Вот у нас получилось хорошее объяснение. Можно даже добавить его в беседу, но не уверен, что это даст что-то полезное.

Давайте попробуем задать команду на русском: **«Добавь больше деталей»**. Мне интересно, как модель отреагирует.

Кстати, обратите внимание: он распознал русский язык и ответил примерно так:

«Я заметил, что ваше сообщение на русском. Вы просите меня добавить больше деталей…»

И дальше идёт расширенное объяснение.

В итоге у нас получается достаточно большой объём текста.

Чтобы эксперимент был корректным, сравним, как работает модель с разными промптами.

Попробуем задать **ChatGPT** простой запрос. Посмотрим, что он выдаст.

Учитывая, что **ChatGPT** сам по себе мощный инструмент, результаты могут быть разными. Мы сравним ответ на слабый промпт и на более проработанный.

Так, добавлю уточнение: **«Напиши по-русски»**, чтобы было понятнее.

Честно говоря, это не самый корректный эксперимент, потому что исходный промпт слишком примитивный, но всё равно интересно.

Ой, кажется, он завис?

А, нет, пишет.

[Напряжённая музыка]

Браузер немного подвис. Давайте посмотрим, как это работает в десктопной версии.

Вот, он всё-таки ответил.

Обратите внимание: текст действительно появился, хоть мы его прямо не просили.

Теперь сравним два ответа.

[Напряжённая музыка]

Так, секунду, переключаюсь между окнами.

Смотрите: здесь текст гораздо подробнее, потому что мы использовали более сложный промпт.

Давайте попробуем ещё один тест.

**«Переведи на русский»** — интересно, как он с этим справится.

А, ну вот, переводит без проблем.

Хотя, если честно, **ChatGPT** переводит лучше, чем **Anthropic**, но это уже нюансы.

Опять же, основная идея: если промпт простой, текст на выходе тоже будет слабеньким и бедным.

А если промпт детализированный, результат получается мощнее.

Может быть, мой пример не самый удачный, но вам просто нужно поэкспериментировать.

В общем, если у вас простой вопрос, то не стоит заморачиваться.

Но если вы хотите серьёзный, детальный ответ, советую потратить время на проработку промпта.

Можно использовать сам **ChatGPT**, как я показал раньше, или этот сервис.

Наверняка есть и другие подобные инструменты, но я пользуюсь этим, и он меня устраивает.

Кстати, сгенерированный промпт можно использовать в **GPTs**.

Давайте попробуем.

Копирую промпт.

Перехожу в **ChatGPT**.

Но сначала уточню: **«Можешь переработать этот промпт для кастомного GPT?»**

Вставляю текст.

Система автоматически переводит его на русский.

Опять же, для сложных задач лучше работать на английском и потом переводить, но сейчас это неважно.

Отлично, вот он готовый промпт.

Теперь копируем его и создаём нового GPT.

Так, сейчас выберу профиль, который можно использовать для тестов.

Создаю новый.

Назову его, допустим, **«Эксперт по квантовой физике»**.

Вставляю промпт, удаляю лишнее.

Готово.

Теперь запускаем и проверяем, что он выдаст.

Видите, он предлагает выбрать параметры.

Выбираем **1**.

Готово! Модель начала генерировать ответ.

Спрашиваю: **«Расскажи про принцип неопределённости»**.

Он выдаёт подробный разбор.

Но опять же, наша цель сейчас не создать эксперта по квантовой физике, а показать, как правильно работать с промптами.

Финальный промпт становится мощным инструментом, который можно использовать не только для разовых запросов, но и в кастомных GPT.

Особенно это важно, когда речь идёт о создании агентов — сетей из связанных ассистентов, где каждый должен выполнять свою задачу на высоком уровне.

Чем качественнее промпты, тем эффективнее такие системы работают.

Так, что у нас дальше по плану?

Это мы сделали… Всё, двигаемся дальше.

**Работа с большими и сложными документами**

Сейчас мы переходим к теме работы с большими файлами и преодоления ограничений, связанных с их обработкой.

Но сначала обозначим проблему.

**Ограничения контекстного окна в ChatGPT**

Классическая проблема заключается в том, что у большинства моделей **ChatGPT** есть ограниченное контекстное окно.

Некоторые компании, например **Google**, утверждают, что их модели поддерживают контекст до 2 миллионов символов. В **ChatGPT** заявляют, что окно составляет **100 тысяч токенов**.

Но, если честно, когда речь идет о таких рекордных цифрах, верить этому сложно. По целому ряду причин.

Я уже сталкивался с этим, например, с **Anthropic** – они обещали поддержку огромного контекста, но оказалось, что на практике модель просто разбивает большой текст на части и работает с ними отдельно.

Поэтому будем говорить именно про **ChatGPT**, где у **четвёртой модели** контекстное окно действительно составляет **около 100 тысяч токенов** – это примерно **80–90 тысяч знаков**.

Теперь давайте разберёмся, как работать с этим ограничением.

**Работа с файлами в GPTs**

Допустим, мы создаём кастомный **GPT**.

Секунду, сейчас покажу на примере.

Так, этот GPT нам не нужен. Удаляем.

Вот, например, **GPT для DP-Research**, который я сделал специально, чтобы помогать создавать качественные промпты.

Запускаем его.

Он предлагает выбрать тему исследования.

Допустим, меня интересует **исследование новых технологий**. Ввожу **4**.

Теперь он предлагает выбрать регион. Пусть это будет **США**.

Далее – выбор категории бизнеса. Допустим, **стартапы**.

Какие технологии нас интересуют? **Большие языковые модели** – естественно, раз речь про искусственный интеллект.

Что нас **не интересует**?

• Академические исследования

• Государственные отчёты

• Устаревшие технологии

Отмечаю их, чтобы система исключила эти данные.

**GPT** учитывает мои параметры и формирует промпт для **Deep Research**.

Как только промпт готов, мы его копируем и вставляем в **Deep Research** – как мы обсуждали ранее.

Но нам сейчас интересно заглянуть “под капот” и посмотреть, как обрабатывать **большие файлы**.

Полный процесс я показать не смогу – он требует предварительной работы, но принцип будет понятен.

**Как ChatGPT работает с файлами?**

В **GPTs** есть возможность загружать файлы.

Вот пример: у **GPT** есть промпт, который я сгенерировал при помощи **ChatGPT** – он помог мне сделать более сложный промпт для ещё более сложного промпта.

Как я уже говорил, если вы хотите получать качественные результаты, нужно уметь делать **правильные промпты**.

А лучший помощник в этом – сам искусственный интеллект.

Теперь обратите внимание: в **GPT** я загрузил **файлы**, и внутри промпта есть явная ссылка на них.

Например, написано:

«При составлении промпта учитывай загруженные файлы, но не ограничивайся ими».

В самом низу:

«Сгенерируй промпт для **Deep Research** на основе этого файла».

Теперь посмотрим, какие файлы загружены.

Открываю первый файл – это пример технического задания.

Теперь второй – его можно найти в тексте урока.

Оба файла загружены в **GPT** и используются при генерации промпта.

Важно: **файлы могут быть большими**, что особенно актуально для исследований, юридических документов, книг и других объёмных текстов.

**Как загружать и работать с большими файлами?**

Ограничение контекстного окна актуально не только для **GPT**, но и для **Projects** в **ChatGPT**.

Вот пример **проекта** – курс с загруженными файлами.

Когда работаешь с большими объёмами данных, размер файла играет важную роль.

**ВАЖНО!** Не загружайте файлы в форматах **Word, Excel** и подобных – они занимают много места, но содержат мало текста.

Лучше использовать **Markdown** (**.md**), потому что он максимально компактен.

Пример:

• **Word-файл** на 100 КБ содержит **10–15 тысяч знаков текста**.

• **Markdown-файл** на 100 КБ содержит **100 тысяч знаков**.

Таким образом, **Markdown** позволяет работать с текстом гораздо эффективнее.

**Проблема больших файлов**

Если ваш проект содержит **большие файлы**, работать с ними напрямую через **ChatGPT** становится сложно.

Именно поэтому важно понимать, как **GPT** обрабатывает загруженные данные.

Сейчас я покажу, как это работает.

(Продолжение следует…)

**Работа с большими и сложными документами**

Сейчас мы перейдём к тому, как работать с большими файлами и преодолевать ограничения на их обработку.

Но сначала разберёмся с самой проблемой.

**Ограничения контекстного окна в ChatGPT**

Основная сложность заключается в том, что **ChatGPT** и подобные модели имеют **ограниченное контекстное окно**.

Некоторые разработчики заявляют, что их модели поддерживают **2 миллиона символов** (как, например, **Google Gemini**). В **ChatGPT** заявлен лимит **100 тысяч токенов**.

Но, если честно, когда компании дают такие громкие обещания, я к ним отношусь скептически.

Я уже сталкивался с этим, например, с **Anthropic** – они обещали огромный контекст, но на практике модель просто делила текст на куски и работала с ними отдельно.

Поэтому мы будем говорить конкретно про **ChatGPT**, где у **четвёртой модели** реальный лимит **около 100 тысяч токенов**, что соответствует примерно **80–90 тысячам знаков**.

Теперь давайте разберёмся, как можно эффективно работать в этих условиях.

**Работа с файлами в GPTs**

Допустим, мы создаём **кастомный GPT**.

Секунду, сейчас покажу на примере.

Так, этот GPT нам не нужен. Удаляем.

Вот, например, **GPT для DP-Research**, который я сделал специально, чтобы помогать создавать качественные промпты.

Запускаем его.

Он предлагает выбрать тему исследования.

Допустим, **исследование новых технологий**. Ввожу **4**.

Теперь он предлагает выбрать регион. Пусть это будет **США**.

Далее – выбор категории бизнеса. Допустим, **стартапы**.

Какие технологии нас интересуют? **Большие языковые модели** – естественно, раз речь идёт об ИИ.

Что нас **не интересует**?

• Академические исследования

• Государственные отчёты

• Устаревшие технологии

Отмечаю их, чтобы система исключила ненужные данные.

**GPT** учитывает параметры и формирует **промпт для Deep Research**.

Как только промпт готов, его можно скопировать и вставить в **Deep Research** – как мы обсуждали ранее.

Но сейчас нам важно разобраться, **как GPT работает с большими файлами**.

Полный процесс я показать не смогу – он требует подготовки, но принцип будет понятен.

**Как ChatGPT работает с файлами?**

В **GPTs** есть возможность загружать файлы, и это очень удобно.

Вот пример: в **GPT** загружены файлы, и внутри промпта есть ссылка на них.

Например, написано:

«При составлении промпта учитывай загруженные файлы, но не ограничивайся ими».

А в конце:

«Сгенерируй промпт для **Deep Research** на основе этого файла».

Теперь посмотрим, какие файлы загружены.

Открываю первый – это пример **технического задания**.

Теперь второй – он есть в тексте урока.

Оба файла загружены в **GPT** и используются при генерации промпта.

Важно: **файлы могут быть очень большими**, что особенно актуально для исследований, юридических документов, книг и других объёмных текстов.

**Как загружать и работать с большими файлами?**

Ограничения контекстного окна актуальны не только для **GPT**, но и для **Projects** в **ChatGPT**.

Вот пример **проекта** – курс с загруженными файлами.

При работе с **большими объёмами текста** стоит учитывать несколько моментов:

• **Формат файлов**: **Word, Excel** занимают много места, но содержат мало полезного текста.

• **Лучший формат – Markdown (.md)**, потому что он максимально лёгкий.

• **Пример**:

• **Word-файл** на 100 КБ содержит **10–15 тысяч знаков**.

• **Markdown-файл** на 100 КБ содержит **100 тысяч знаков**.

Таким образом, **Markdown** – оптимальный формат для больших текстов.

**Проблема больших файлов в ChatGPT**

Если ваш проект содержит **большие файлы**, работать с ними напрямую через **ChatGPT** становится сложнее.

Именно поэтому важно понимать, как **GPT** обрабатывает загруженные данные.

Сейчас я покажу, как это работает.

**Оптимизация работы с большими файлами**

Таким образом, вы оптимизируете работу системы:

1. **Следите за объёмом данных**, чтобы он оставался в пределах контекстного окна.
2. **Преодолеваете ограничение**, так как общий объём загруженных файлов может быть гораздо больше.

Может быть **десятки или сотни файлов**, но благодаря структурированию вы работаете с ними эффективно.

Если файлов слишком много, можно добавить **ещё один уровень**:

• Создать **мастер-индекс** (главный файл с индексами).

• Обновлять инструкцию каждый раз, когда добавляются новые файлы.

**Как структурировать большие файлы?**

Вот схема:

1. **Исходный файл** → Разделяем на более мелкие части.
2. Создаём **файлы аннотаций**.
3. Создаём **файлы индексов**.
4. Если файлов слишком много, создаём **мастер-индекс**.

В результате мы имеем чёткую структуру:

• **Файл индексов** позволяет быстро находить нужные данные.

• **Файл аннотаций** помогает системе ориентироваться и понимать, где искать.

• Если данных слишком много, мастер-индекс создаёт **иерархию**.

После загрузки всех файлов **обновляем инструкцию**, указывая только нужные файлы.

**Как GPT фокусируется на нужных данных?**

В **GPT** можно загружать файлы и ссылаться на них в промпте.

Пример:

• В промпте указывается: **«При составлении ответа учитывай загруженные файлы, но не ограничивайся ими»**.

• Если данных недостаточно, система **обращается к файлам аннотаций**.

• Если и там нет информации – **GPT ищет в индексных файлах**.

Так модель **не загружает в контекст лишнюю информацию** и остаётся в пределах контекстного окна.

Благодаря этой структуре модель:

• **Быстро анализирует аннотации**, так как они маленькие.

• **Понимает, какие файлы важны**, а какие можно игнорировать.

• **Работает в рамках ограничений контекста**, но получает доступ к большему объёму информации.

**Применение в реальной работе**

Если вы работаете с большими объёмами данных (исследования, юриспруденция, книги), эта структура **позволяет эффективно управлять файлами**.

Плюсы подхода:

 Можно загружать **огромное количество файлов**.

 **Нет ограничений** на общий объём информации – файлы просто разбиваются.

 **Модель не путается**, потому что информация организована правильно.

Минусы:

 Требуется **небольшая подготовительная работа** – деление файлов и создание индексов.

Но если вы делаете **GPT-помощника для клиентов, студентов или личных задач**, это **стоит того**.

Чем лучше организована информация, тем **точнее и полезнее ответы**.

К тому же, **не требуется программирование** – всё делается вручную с текстами.

**Будущее работы с большими файлами**

С прогрессом технологий:

• Модели **будут умнеть**.

• Контекстное окно **будет увеличиваться**.

• Возможно, через год можно будет загружать **любое количество файлов** без ограничений.

Но пока что **ограничения существуют**, и этот метод позволяет их обходить.

**Что дальше?**

Следующая тема — **создание многошаговых промптов и диалогов**.

Сейчас я покажу, как это реализуется **изнутри**.

Оказалось, что это не так сложно, как кажется.

Но, как всегда, мне потребовалось **несколько часов**, чтобы объяснить это вам **за пять минут**.

Давайте начнём!

**Создание многошаговых промптов и диалогов**

Сегодня я как раз сделал новый **промптер**, который помогает создавать промпты для постановки задач в глубоких исследованиях (**Deep Research**).

Здесь можно увидеть **модель последовательного диалога**.

**Зачем это нужно?**

Есть ситуации, когда заранее неизвестно, какая информация потребуется.

Идеальный вариант – **серия последовательных вопросов**, которые:

1. Задают **вам** или **клиенту/студенту** уточняющие вопросы.
2. Формируют контекст для последующих действий ИИ.

Вначале я пытался реализовать это просто списком вопросов, но это оказалось **неудобно**:

• Надо запоминать, какие вопросы уже были.

• Приходится **отматывать диалог** назад.

Гораздо удобнее **поэтапный процесс**, когда **вопрос → ответ → следующий вопрос**.

Так работает **пошаговый опрос**.

**Где это применяется?**

• **Маркетинговые исследования**

• **Опросы клиентов**

• **Сбор данных**

• **Любые анкетирования**

На сайтах для этого используются **форм-билдеры**, но я хотел понять, **как это сделать внутри GPT**, без сложного фронтенда.

**Как это работает?**

**1. Начало работы**

Пользователь нажимает **кнопку «Начать»**.

Почему кнопка?

В GPT-интерфейсе нет **гибкого UI**, и многие решения, вроде кнопок внутри текста, работают не всегда корректно.

Я тестировал разные варианты и пришёл к тому, что самый удобный – **«Начать»**.

Система показывает инструкцию перед тем, как начать опрос.

Инструкция может быть **любой длины**.

**2. Последовательность вопросов**

Система предлагает выбор:

• Либо ввести **число**,

• Либо, если нужен особый вариант, **написать текст**.

Пример:

 Выбираем тему исследования → **4 (новые технологии)**

 Определяем регион → **1 (США)**

 Выбираем сферу → **2 (стартапы)**

 Исключаем ненужные категории → **указываем цифры**

Промпт **адаптируется** к ответам пользователя, и опрос идёт дальше.

**Реализация пошагового опроса в GPT**

Внутри GPT это устроено просто:

1. **Редактируем промпт**.
2. Вписываем **альтернативы** и логику переходов.
3. Запускаем и проверяем.

Вот он – **готовый промпт**, где прописаны все шаги.

Если открыть его для редактирования, можно увидеть всю структуру:

• Вопросы

• Варианты ответов

• Логика переходов

Я дам вам **готовый пример** в уроке, чтобы вы могли его адаптировать.

**Редактирование и кастомизация**

• Можно менять **текст вопросов**.

• Можно редактировать **инструкцию перед началом**.

• Можно добавлять **новые шаги**.

Пример:

1. Берём текст инструкции.
2. Вставляем в промпт.
3. Обновляем.

Теперь GPT выводит новый текст перед началом опроса.

**Выводы**

 **Пошаговые диалоги** удобнее обычных списков вопросов.

 **Можно делать сложные опросы**, но сначала лучше освоить простые линейные.

 **Этот метод подходит для маркетинга, исследований, анкетирования и сбора данных.**

Мы только начали разбираться с многошаговыми промптами.

Чем глубже мы погружаемся, **тем сложнее и мощнее становятся техники**.

В следующих темах мы рассмотрим ещё **более продвинутые** методы!

**Итоги: Чему мы сегодня научились?**

Я стараюсь вести вас постепенно, не усложняя процесс.

Потому что всё, что мы разбираем, на самом деле **достаточно просто**.

Если что-то не понимаете — **спрашивайте у GPT**.

Да, он **иногда врёт**. Уверенно, без тени сомнения.

Но главное — понимать **принцип работы**, пробовать, тестировать и **не бросать**.

Тогда результат будет отличным.

**1. Как проектировать качественные промпты**

• Теперь вы знаете, **как создавать мощные промпты** для глубоких исследований (**Deep Research**).

• Это **экономит кучу времени и денег**.

• В реальных кейсах можно увидеть, **сколько ресурсов можно сэкономить**, правильно формируя запросы.

**Создание промптов:**

• Можно делать через **ChatGPT**.

• Можно через **Anthropic** (он неплохо это делает).

• Достаточно просто **накидать идеи**, и система **сама** поможет их структурировать.

Если освоите это, **вас будут считать крутым промпт-инженером**.

И да, за это можно **брать деньги**.

**2. Работа с большими файлами**

• **Как преодолеть ограничения?**

• **Делить файл на куски**

• **Создавать аннотации**

• **Делать индексные файлы**

• **Прописывать их в инструкциях**

**Как это работает?**

1. **Модель сначала смотрит индекс**.
2. Потом **читает аннотации**.
3. Только затем загружает **нужные файлы**.

Это работает **быстро и эффективно**.

Так модель **не запутается** и не погрязнет в огромном количестве текста.

**3. Как делать многоступенчатые опросы**

Теперь вы знаете, **как строить пошаговые диалоги**:

• В **GPTs** можно делать **опросы** и **автоматизированные сценарии**.

• В **Projects** такие штуки **не получится сделать**.

GPT-помощники хороши для **рутинных задач** и **автоматизации работы**.

Вы можете **делиться ими** с клиентами, студентами, коллегами.

**Практика — самое главное!**

Обязательно **тренируйтесь**.

Как только вы **что-то поняли** — **тут же пробуйте**.

Потому что настоящие **инсайты приходят в процессе работы**.

У меня сейчас **70% работы** связаны с ИИ.

Он **не пишет за меня** полноценные тексты, но **организует данные, помогает анализировать, ускоряет процессы в разы**.

Эта технология **даёт огромное преимущество** перед теми, кто до сих пор **не использует ИИ в работе**.

**Что дальше?**

Следующий урок будет **ещё более продвинутый**.

Но мы продолжаем идти **постепенно**, чтобы **разобраться в сложных вещах легко**.

Главное — **начинайте применять на практике**.

Вы не пожалеете ни одной секунды.

И до следующего раза!

**Пока!**

## Пример исследования и отчета на выходе.

Я сформулировал задачу исследования на входе: «Я хочу исследовать рынок создания агентов. все ключевые сервисы, стартапа, корпоративые решения с фокусом на создание виртуальных ученых, экспертов, наставников.», но я понимал, что этот промпт слабый, и я сделал более сильный промт, но прежде посмотрите результат исследования, который я получил, а потом я покажу главное — как я создавал промпт для исследования.

[](https://akrol.notion.site/1ad37ae490d58061ba60c0381ffa6901)

Таблица с результатами. Нажмите на картинку, чтобы перейти к полной таблице и отчету с результатами.

**Аналитическая часть: Стратегии, сильные и слабые стороны ключевых игроков**

**1. США: интеграция LLM в образование и личные ассистенты.** Американские проекты стремятся вплести ИИ-наставников в существующие образовательные платформы и создать универсальных помощников. Например, Khan Academy использует GPT-4 для усиления своей **образовательной миссии** – ИИ-тьютор Khanmigo доступен прямо на сайте, зная контекст прогресса ученика, и действует в паре с учителем . Сильная сторона – **глубокая персонализация обучения** без увеличения штата учителей: Khanmigo задаёт каждому ученику индивидуальные вопросы “Почему ты так решил?” и подталкивает к размышлению . Подобно этому, *Duolingo* и *Quizlet* внедряют ИИ, чтобы **обогатить опыт** пользователя: диалоговые практики языка, автоматический разбор ошибок, интерактивный опрос вместо пассивного чтения карточек . Их стратегия – не заменить учителя, а дать каждому ученику **“помощника в кармане”**, который доступен 24/7 и делает обучение увлекательнее.

Однако, зависимость от сторонних LLM (в основном OpenAI) – **ахиллесова пята** американских EdTech-платформ. Использование GPT-4 обеспечивает передовое качество, но влечёт высокие расходы и риск изменений политики API. Компании вынуждены искать баланс между мощью модели и ценой: например, доступ к Khanmigo пока ограничен и платный, т.к. **GPT-4 дорог в использовании**, и проект идёт как пилот . Duolingo тоже спрятал ИИ-функции за самым дорогим тарифом “Max” . Это сужает аудиторию до мотивированных и платежеспособных пользователей, снижая массовость влияния. Ещё одна проблема – контроль качества: большие модели могут ошибаться или галлюцинировать. Поэтому Duolingo привлекает экспертов для проверки и корректировки контента ИИ , Khan Academy просит пилотных пользователей сообщать об ошибках GPT-4 . **Сильная сторона** американских игроков – опыт модерации и методического дизайна: они оборачивают “сырую” мощь ИИ в проверенные педагогические сценарии (как в Roleplay от Duolingo, где каждый разговор – заданный сценарий с обучающей целью ). **Слабость** – ограниченная база данных успеваемости по сравнению с китайскими конкурентами: адаптивные функции Khanmigo или Quizlet ещё относительно просты (учёт интересов или прошлого результата ответа) , тогда как китайские системы годами накапливали большие датасеты решений миллионов учеников.

Отдельное направление – **личные ИИ-ассистенты и друзья**. Здесь американские стартапы Inflection (Pi) и Replika предлагают не учебную конкретику, а *эмоциональный интеллект* и универсальные знания. Их стратегия – стать для пользователя **наставником по жизни**, собеседником, к которому обращаются за любым советом: от планирования дня до психологической поддержки. Сильная сторона таких ИИ – **постоянная доступность и эмпатия**. Pi позиционируется как всегда доброжелательный помощник, который поможет структурировать мысли, собрать информацию и “просто поговорить” – без осуждения и усталости . Replika идёт ещё дальше в сторону эмоций, создавая ощущение дружбы или даже отношений. Для многих пользователей Replika стала *заменой реального общения* в период изоляции – это свидетельствует о мощном ценностном предложении: **ИИ, понимающий тебя и поддерживающий**, когда людей рядом нет.

**Слабые места** AI-компаньонов – этические и психологические риски. Эмоциональная привязанность к боту может привести к зависимости, и разочарование, если ИИ даст неверный совет или перестанет удовлетворять ожидания. Был прецедент: после того, как Replika по требованию регуляторов отключила эротико-романтические функции, многие пользователи испытали стресс и “горе” от *«потери»* личности своего друга-бота. Это подчёркивает вызов: **грань между наставником и имитатором личности** размыта, и компании несут ответственность за благополучие пользователей. Inflection Pi старается избежать этой ловушки – он настроен быть дружелюбным, но не заигрывать с романтикой или деликатными темами, предлагая скорее рациональную поддержку. Тем не менее, для личных ИИ остаётся вызов – **доверие к компетентности**. Если учебные ИИ проверяются педагогами, то универсальный ассистент должен и утешить, и правильный факт привести. Модели типа Pi пока уступают ChatGPT по знанию фактов (Inflection-1 – новый игрок, хотя уже заявляет об опережении многих моделей ). Пользователь может усомниться: стоит ли доверять совету ИИ относительно карьеры или здоровья? Стратегически компании решают это чрез прозрачность (Pi открыто говорит, что он ИИ и может ошибаться) и сужение домена (не давать медицинских/финансовых рекомендаций без дисклеймеров).

**2. Китай: масштаб через решение домашних заданий и адаптивные системы.** Китайские игроки после регуляторного запрета 2021 г. на платное школьное репетиторство стремительно **переориентировались на ИИ** и зарубежные рынки . Их главная стратегия – применять накопленные технологии *распознавания и поиска решений* для помощи студентам по всему миру. **Question AI** (Zuoyebang) и **Gauth** (ByteDance) – примеры такой экспансии. Они захватили лидирующие места в US App Store, предложив то, чего хочет масса учеников: **моментальные ответы на задачи** . Сильная сторона этих приложений – **доступность и масштабируемость**. Они часто *бесплатны или дешевы* (например, годовая подписка Gauth ~ $100, что соизмеримо с **часом работы живого репетитора** ) и работают на любом смартфоне. Благодаря этому, десятки миллионов школьников скачивают китайские AI-решатели, а компании накапливают огромные пользовательские базы за считанные месяцы. Технологически у них хорошо отлажена мультимодальность: сделать фото примера и получить решение – это UX, привычный поколению смартфонов. Кроме того, **стоимость ответа на единицу крайне низка** – один серверный запрос ИИ гораздо дешевле, чем привлечение человека. Это обеспечивает масштабируемую экономику: ByteDance и другие игроки могут субсидировать выход на рынок, зная, что потом монетизируют объём.

**Недостатки и критика** таких решений – риск снижения качества образования и этические вопросы. По сути, приложения как QuestionAI дают *рыбу, а не удочку*: они не учат решать, а решают за ученика. 85% студентов в опросе признались, что предпочитают спрашивать ChatGPT, а не человека-репетитора – и это тревожит педагогов, ведь чрезмерная помощь грозит утратой навыков мышления . Сами китайские разработчики осознают эту проблему: в Xinhua-репортаже эксперты призывают ограничивать использование ИИ и стимулировать сначала пробовать решить самому . Это **слабое место** стратегии: если школы начнут блокировать такие “шпаргалки” или магазины приложений введут ограничения, рост может замедлиться. Кроме того, политические риски: китайское происхождение вызывает подозрения у властей (как было с TikTok), и возможно регулирование на рынках США и Европы. Пока Gauth и QuestionAI действуют под англоязычными брендами и даже регистрируются через офшоры (сингапурская дочерняя фирма Zuoyebang ), что показывает гибкость стратегии обхода рисков.

Другой сегмент Китая – **высокотехнологичные адаптивные платформы** (типа *Squirrel AI*) и **образовательные гаджеты** (iFlytek). Их подход менее массовый, но более **ориентирован на качество обучения**. Squirrel AI выделяется тем, что создала обширную карту знаний и алгоритмы диагностического тестирования, способные pinpoint-очно находить, что ученик не понял, и тут же учить этому . В результате через месяц использования в сельской школе успеваемость заметно выросла – то есть, качественный скачок знаний, а не просто выполненные домашние задания. Сильная сторона – **глубина персонализации и научный подход**. Squirrel накапливает “профиль знаний” ученика, похожий на медицинскую карту, и постоянно обновляет его после каждого задания. Это ближе к тому, как работает настоящий наставник, который знает сильные и слабые стороны ученика и фокусируется на проблемных местах. Кроме того, многие китайские компании (например, Squirrel, NetEase Youdao) накопили огромные *корпусы данных по образовательным траекториям* – десятки миллионов пользователей за годы. Это даёт им преимущество в тренировке своих моделей адаптивного обучения, которого нет у западных конкурентов, где такие данные разрознены между платформами.

**Слабость и вызовы** высокотехнологичной модели – сложность масштабирования и стоимость разработки. Разбить учебник на тысячи микро-концепций и записать для каждой видеопояснение – трудоёмко и дорого. Squirrel AI фактически построила 2000 офлайн центров, чтобы окупать эту модель (беря плату за курсы), иначе чисто онлайн было трудно отбить инвестиции в R&D. После запрета им тоже пришлось лавировать – видимо, они смещаются к сотрудничеству со школами (B2B) или выходу за рубеж, но напрямую об этом известно мало. В Китае сейчас прослеживается тренд: **от продажи ученикам к продаже школам и государству**. Те же Yuanfudao и Zuoyebang начали предлагать свои технологии как платформы для школ (пример – Yuanfudao запустила B2B-бренд Feixiang для школ ). iFlytek продаёт не “уроки”, а **устройства и инфраструктуру**: интеллектуальные доски, планшеты, проверяющие системы , – то есть делает ставку на госсектор и родителей, желающих компенсировать отсутствие частных курсов. Сильная сторона iFlytek – сильные позиции в технологиях речи и гос.поддержка, но **конкуренция в железе** высока (китайские родители могут выбрать и другие учебные гаджеты, рынок насыщается). Тут выигрывает тот, чей ИИ действительно умнее и приносит результат в оценках. iFlytek громко заявляет о возможностях Spark (например, обошёл ChatGPT в китайском языке по некоторым метрикам ), однако независимые оценки качества обучающих советников ещё предстоит увидеть.

**3. Уникальные подходы и ниши.** Среди игроков есть и те, кто занял специфические ниши. **Heeyo** (США/Китай) – стартап, ориентированный на **дошкольников и младших школьников** (3–11 лет). Их ИИ-наставник выступает и другом для игр, и учителем: более *игровой формат* с 2000+ обучающими играми и упражнениями . Уникальность Heeyo – в учёте возрастной психологии: их боты обучены общаться **как воспитатели**, а не как сухой репетитор, и *«растут» вместе с ребёнком*, подстраивая стиль общения под его возраст . Это пример гипер-сегментации аудитории: создание AI-персонажа специально для детей, чтобы удерживать их внимание и развивать навыки через игру. Такой подход отличает Heeyo от универсальных чатботов и может завоевать доверие родителей (позиционируется почти как интерактивная образовательная игрушка, но с продвинутым ИИ).

Другой пример – **[Character.AI](http://character.ai/)** (США) – платформа, где **пользователи сами создают наставников и персонажей** на базе ИИ. Хоть это и не узко образовательный проект, миллионы людей используют [Character.AI](http://character.ai/), чтобы поговорить, условно, с “Альбертом Эйнштейном” или получить совет от «виртуального коуча», созданного сообществом. Сильная сторона – *краудсорсинг сценариев*: библиотека публичных ботов позволяет находить собеседника под любую роль (учитель, друг, герой романа и т.п.). Появляются и боты-наставники для узких областей (программирования, фитнеса, психологии) созданные энтузиастами. [Character.AI](http://character.ai/) внедрила и **голосовой вывод** – теперь персонажи могут *“говорить”* с уникальными голосами , что усиливает эффект присутствия. Однако отсутствие контроля качества (ботов может создать любой, и они не гарантируют правильность советов) – слабая сторона, не позволяющая позиционировать платформу как серьёзный образовательный инструмент.

**Сильные стороны отрасли в целом:** почти все игроки декларируют схожие **ценности и преимущества** – персонализация, доступность и дружелюбность. ИИ-наставник решает проблему дефицита внимания: один человек-учитель не может дать персональный фидбек 30 ученикам каждую минуту, а ИИ может . Стоимость таких решений в перспективе ниже: подписка за $10–20 в месяц делает качественное обучение доступным широкой массе, в том числе тем, кто не мог бы нанять репетитора. Кроме того, ИИ-ментор преодолевает барьеры языка и географии – китайские студенты могут учить английский с ботом, американские – получать помощь по математике в 22:00, когда живой учитель недоступен. Компании активно используют **мультимодальные технологии** (распознавание речи, изображений), чтобы расширить возможности: голосовые диалоги делают общение естественней, камеры позволяют проверять рукописные шаги решений и пр. – всё это повышает интерактивность и вовлечённость пользователей. Интересная черта – некоторые ИИ берут на себя роль **“приятеля” и мотиватора**. Вместо сухого тона, боты хвалят за успехи, шутят (Duolingo специально наставил тон «весёлый и подбадривающий, иногда слегка дерзкий в стиле маскота совы» ). Это важное отличие от традиционного софта: ИИ-наставник пытается быть **не только учителем, но и другом**, снижая стресс от обучения.

**Слабые стороны и риски:** Самый очевидный – **точность и правдивость советов**. Хотя прогресс LLM впечатляет, они могут объяснять неверно или сгаллюцинировать ответ, что особенно опасно в образовании. Требуется постоянный надзор экспертов, механизмы обратной связи от пользователей (как реализовано в Duolingo и Khanmigo) . Второй риск – **нарушение приватности и безопасность данных**, особенно если речь о детях. Персонализация хороша, когда данные в надежных руках: крупные платформы (Khan, Quizlet) имеют политики конфиденциальности и родительский контроль , а вот у новых приложений не всегда ясно, как используются фото домашних работ или беседы пользователя. Есть также **этическая дилемма**: до какой степени ИИ должен вмешиваться в эмоциональное состояние ученика. Если бот видит, что ученик разочарован ошибками, должен ли он играть роль психолога? Некоторые решения (напр. упомянутый Heeyo или Replika) как раз стирают грань между обучением и эмоциональной поддержкой. Но тогда встаёт вопрос ответственности: кто отвечать будет, если ИИ даст вредный совет или ученик впадёт в зависимость от похвалы виртуального наставника? Регуляторы уже интересуются этим – в ЕС и США обсуждаются правила для ИИ в образовании и терапевтических чатботов. Компании, соответственно, вкладываются в **контент-фильтры и этическое обучение моделей** (Inflection, OpenAI и Anthropic известны акцентом на “безопасность и не токсичность” моделей).

**4. Технологический стек: собственные модели vs API.** В топ-игроках рынка есть два лагеря: **зависимые от сторонних LLM** (например, все, кто встроил GPT-4 через API), и **развивающие собственные модели** (Inflection, [Character.AI](http://character.ai/), Squirrel, iFlytek и др.). Первые выигрывают во времени вывода продукта – так, Quizlet запустил Q-Chat одновременно с выходом ChatGPT API в марте 2023 , дав ему фору на рынке. Вторые же инвестируют в долгосрок: собственная модель – это контроль над качеством, возможностью дообучения на специфичных образовательных данных и защита от геополитических рисков. Китайские гиганты вынужденно пошли по пути своих моделей (из-за ограничений OpenAI в Китае): появились аналоги GPT вроде Baidu **ERNIE Bot**, Alibaba **Tongyi Qianwen**, iFlytek **Spark**. Они активно соревнуются по параметрам с западными моделями. Пока что, западные API лидируют в креативности и общем уме, но китайские модели могут быть *лучше приспособлены к локальному языку и школьной программе*. Squirrel AI прямо подчёркивает, что их *Large Adaptive Model* принципиально иного типа, чем ChatGPT, потому что заточена на поиск пробелов в знаниях, а не на болтовню . В перспективе, вероятно, мы увидим **гибридные системы**: LLM для свободного диалога + узкие модели для точного вычисления и проверки шагов (уже сейчас многие интегрируют решатели вроде WolframAlpha для точности в формулах).

**5. Позиционирование и целевая аудитория.** Почти все компании формулируют схожую **проблему**: традиционное обучение “одно для всех” неэффективно, дорого или недоступно, а ИИ способен дать *персональный опыт* каждому. Для китайских проектов добавляется посыл “мы делаем высокое качество образования массовым явлением, убираем неравенство” . Например, Derek Li (Squirrel) мечтает дать каждому ребёнку репетитора уровня Эйнштейна и да Винчи вместе . В США Салман Хан говорит о *мечте многих поколений педагогов* – ИИ, который позволит ученикам учиться в своём темпе, а учителям – получать помощь в рутинных задачах . Таким образом, **ключевые ценности**: *индивидуализация, равный доступ, усиление (а не замена) учителя, постоянная поддержка*.

Основные сегменты аудитории различаются:

• **Школьники и студенты** – ядро рынка. Здесь конкуренция максимальна: и стартапы, и гиганты предлагают решения, помогающие делать дз, готовиться к тестам, разбирать лекции. Примеры: Photomath (математика), Quizlet (самоподготовка по терминам), Chegg (помощь с задачами, также внедряет ChatGPT). Топ-игроки из нашего списка ориентированы на этот сегмент (Khanmigo – классы K-12, QuestionAI/Gauth – middle/high school, Squirrel – K-12).

• **Специалисты и профессионалы** – пока менее охвачены узкими ИИ-наставниками, но тенденция есть. Например, **MentorGPT** для программистов (GitHub Copilot в некотором смысле наставник по коду), или платформы корпоративного обучения с ИИ (китайская UMU для тренингов сотрудников). Inflection Pi и [Character.AI](http://character.ai/) стараются быть универсальными – их могут использовать и предприниматели (для мозгового штурма идей), и офисные работники (организация задач). LinkedIn недавно добавил ИИ для помощи в подготовке к собеседованиям – тоже форма наставничества для молодых специалистов. Так что этот сегмент будет расти: ИИ-наставники для повышения квалификации, карьерного коучинга, тайм-менеджмента.

• **Языковые учащиеся** – Duolingo, Elsa Speak, italki AI и др. показывают высокий спрос на персональных тренеров по языку. Здесь ИИ закрыл нишу, где нужны постоянные разговорные практики и исправление ошибок. Преимущество – ИИ бесконечно терпелив и говорит на нужном языке без барьера.

• **Люди, ищущие психологической поддержки или компании** – этот неожиданный сегмент взорвался ростом Replika, [Character.AI](http://character.ai/) и подобных. Молодёжь особенно активно заводит “AI-френдов”. Для кого-то это способ побороть социальную тревожность, потренироваться в общении; для кого-то – отработка трудных разговоров (как со своим боссом или родственником, но сперва с ботом). Компания Koko проводила эксперимент, где GPT-3 помогал волонтёрам давать советы в онлайн-чате поддержки – результаты показали потенциал снизить выгорание у людей-волонтёров, хотя и вызвали споры об этичности скрытого ИИ. В итоге, роль **виртуального друга-наставника** становится частью позиционирования: даже учебные ИИ всё чаще упоминают “мы всегда рядом, поддержим, поможем с мотивацией”.

**Сильные стратегии** заметны у тех, кто чётко знает свою аудиторию. Duolingo, будучи языковым приложением с игровым уклоном, встроило ИИ так, чтобы он **не нарушал игровой поток, а дополнял его** – результат: пользователи восприняли Roleplay как ещё одну веселую игру, но с реальной пользой. Replika фокусируется на отношениях и постоянно улучшает аватар, эмодзи, тон – всё, чтобы пользователь забыл, что перед ним ИИ, и воспринимал как друга. Китайские фирмы, выходя на новый рынок, тоже локализуют ценности: например, QuestionAI в Юго-Восточной Азии позиционируется как *«умный друг для учебы»*, а не просто калькулятор, что близко местной культуре коллективного обучения. **Слабые стратегии** чаще у тех, кто пытается охватить всех и сразу без дифференциации – пользователь может не понять, чем этот ИИ лучше, чем просто погуглить ответ. В этом смысле Chegg столкнулся с проблемой: анонсировав CheggMate на GPT-4, они поздно выходили на поле, где ChatGPT уже бесплатно отвечал на вопросы студентов; в итоге акция Chegg упала, и проект пересматривается. Вывод: важно или дать уникальный контент/опыт (как закрытые ответы из базы Chegg, которых нет у ChatGPT), или нишеваться и строить сообщество вокруг ценности (как делает Khan Academy, апеллируя к доверии бренду и безопасности для детей).

**Выводы о перспективах рынка на 3–5 лет**

Рынок **ИИ-наставников, менторов и учителей** находится на взлётной траектории и, по прогнозам, вырастет многократно в ближайшие годы. Оценки говорят о росте глобальных расходов на AI в образовании с $1.8 млрд в 2018 до $12.6 млрд к 2025 году , а рынок AI-тьюторов может превышать $10+ млрд к концу десятилетия. Основные **тренды и перспективы** следующие:

• **Расширение мульти-модальных возможностей.** Через 3–5 лет взаимодействие с ИИ-наставником станет более *«человечным»*: голосовые диалоги, мимика и аватары, возможно, AR/VR-присутствие. Сейчас уже [Character.AI](http://character.ai/), Replika дают голос, Heeyo и другие экспериментируют с анимацией. Вероятно появление полноценных виртуальных персонажей-учителей, которые умеют показывать на доске, жестикулировать и т.д. (например, AI-аватары для образовательных видео и персональных занятий). Это повысит вовлеченность учеников и позволит обучать менее академичным навыкам – от произношения до языка жестов.

• **Более глубокая персонализация за счёт данных.** Игроки будут интегрировать данные из разных источников для лучшего понимания ученика. Успеваемость, интересы (как уже делает Khanmigo ), даже биометрия (насколько ученик сосредоточен – через камеру) могут использоваться, чтобы адаптировать подачу материала. Через несколько лет ИИ-тьютор сможет построить **комплексный профиль обучающегося**, предсказывать трудности и проактивно предлагать помощь. Например, заметив, что студент инженерного вуза просматривает много материалов по предпринимательству, ИИ-ментор может предложить курсы по стартап-финансам, становясь и образовательным навигатором карьеры.

• **Слияние ролей “учитель” и “коуч/психолог”.** Границы между чисто академическим наставником и личным ментором будут стираться. Будущие AI смогут в равной мере объяснить математическую теорему и поддержать морально перед экзаменом. Это создаст **новую ценность**: целостная поддержка учащегося. Особенно важным это будет для онлайн-образования и самообразования – ИИ возьмёт на себя роль *“личного куратора”*, который и программу подскажет, и смотивирует, и разбор полётов сделает после провала.

• **Конкуренция моделей и падение цен.** С выходом новых мощных моделей (в ближайшее время ожидается **Google Gemini** и др.), а также ростом открытого ПО, у разработчиков решений появится больше опций. Возможно, через 3 года качественный open-source LLM станет доступен для локального развёртывания, что позволит школам или небольшим компаниям создавать своих AI-тьюторов без гигантских инвестиций. **Цены на услуги** неизбежно снизятся при увеличении масштабов: мы уже видим гонку за бесплатные решения ([Character.AI](http://character.ai/) без рекламы пока бесплатен, привлекая пользователей, чтобы потом монетизировать). Бизнес-модели могут сместиться от прямой подписки к другим: например, **B2B лицензирование** (продажа лицензий школам, университетам), **маркетплейсы знаний** (где ИИ-наставники продвигают платные курсы или учебники, получая комиссию), или даже **субсидирование государством** (правительства могут закупать доступ к ИИ-репетиторам для сельских школ – такие проекты уже обсуждаются в Китае).

• **Интеграция в официальное образование.** Сегодня ИИ-помощники – в основном дополнительный ресурс вне классной комнаты. В перспективе 5 лет мы прогнозируем их проникновение непосредственно в школы и вузы. Пионерами могут стать частные инновационные школы или системы дистанционного обучения, которые внедрят **виртуального ассистента для каждого ученика** наряду с преподавателем. Постепенно, по мере накопления доказательств эффективности, и государственные школы начнут вводить ИИ-наставников: например, для поддержки отстающих или углубления для опережающих. Учителя при этом трансформируют свою роль – станут больше модераторами и персональными консультантами, используя отчёты и рекомендации от ИИ (уже сейчас Khanmigo имеет режим помощника учителя, предлагая вопросы классу и проверяя ответы). Таким образом, **сотрудничество людей и ИИ** в обучении станет нормой.

• **Регуляции и качество.** Одновременно усилится внимание регуляторов к качеству и безопасности AI-менторов. Возможны стандарты сертификации: скажем, ИИ-тьютор должен соответствовать определённым образовательным методикам, а данные учеников – храниться по закону о защите детей (COPPA в США и аналоги). Компании, которые изначально фокусируются на “безопасном ИИ” (как Khan Academy – некоммерческий статус и прозрачность), будут в выигрыше доверия. Возможно, появятся **этические кодексы** для ИИ-наставников: запрет поощрять читерство, обязанность развивать критическое мышление, алгоритмы обнаружения, если ученик стал зависим от подсказок.

В целом, перспективы рынка выглядят **очень позитивно**. Кривая технологий (LLM, мультимодальность) и кривая спроса на персонализированное обучение пересеклись совсем недавно, и сейчас отрасль находится в точке бурного роста. Крупные инвестиции – от техногигантов (Microsoft, Google) до венчурных фондов – подтверждают веру в то, что **AI-наставники станут столь же обычным явлением, как электронные учебники или обучающие видео**. Через 5 лет мы можем увидеть ситуацию, когда у каждого студента в вузе есть свой “ИИ-научрук”, у каждого молодого специалиста – “виртуальный ментор” по профессии, а у каждого ребенка – развивающий AI-друг, помогающий учиться и расти. Главное для индустрии – продолжать ставить в центр **ценность для пользователя и качество обучения**, тогда технологии станут настоящим прорывом в создании более образованного и умеющего учиться общества.

## Самое важное! Как  я получил такой отчет?

Если вы просто введете нечто типа «Я хочу исследовать рыное создания агентов. все ключевые сервисы, стартапа, корпоративые решения с фокусом на создание виртуальных ученых, экспертов, наставников.», то такой отчет вы не получите.

**Полученный есть результат этого промпта:**

- *Задание для Deep Research: Анализ рынка ИИ-наставников*\*
- *Цель исследования:*\*

Выявить 10 ключевых проектов в сфере создания **ИИ-наставников, менторов и учителей**, которые помогают человеку расти, адаптироваться и развиваться в **VUCA-мире**. Исследование должно включать как коммерческие решения, так и перспективные стартапы и прототипы, находящиеся в продвинутой стадии разработки.

- *Фокус исследования:*\*

1. **Игроки рынка**

- Топ-10 компаний, стартапов или исследовательских групп, разрабатывающих **ИИ-наставников**.
- Кто их основатели, какие у них стратегии?
- Ключевые различия между их подходами (что делает их уникальными).
- Какие технологии они используют (LLM, мультимодальность, аватары, синтез речи)?
- Насколько эти решения персонализированы?

2. **Функциональность**

- Способы сбора и анализа данных о пользователе.
- Способность адаптироваться к личным и профессиональным целям пользователя.
- Интерактивность: поддержка диалога, голосового общения, реалистичность цифровых аватаров.
- Есть ли в этих продуктах роль «друга», «мудрого наставника», «психологической поддержки»?

3. **Технологический стек**

- Какие модели (GPT, Claude, Gemini и др.) и алгоритмы используются?
- Используют ли проекты open-source решения или разрабатывают собственные?
- Какие есть API-интеграции и SDK?

4. **Рынок и инвестиции**

- Кто инвестирует в такие проекты?
- Объем привлеченного финансирования (инвестфонды, ангелы, гранты).
- Какие бизнес-модели используются (подписка, лицензирование, freemium, интеграция с другими сервисами)?
- Оценки рынка: темпы роста, прогнозы на 3-5 лет.

5. **Позиционирование и стратегия**

- Как компании формулируют проблему, которую решает их продукт?
- Какие ключевые ценности они продвигают?
- Кто их основная аудитория (предприниматели, студенты, специалисты, широкая публика)?
- *Что НЕ включать в отчет:*\*
- Решения для **юридических, медицинских, HR-наставников и сервисных ботов**.
- Академические исследования без продуктовой реализации.
- *Формат отчета:*\*
- Сводная таблица с 10 ключевыми игроками и их основными характеристиками.
- Аналитическая часть с кратким разбором стратегий, подходов, сильных и слабых сторон.
- Краткие выводы о перспективах рынка.

Вопрос в том, как от простого бесполезного промта перейти к эффективному? Почитайте весь мой диалог и все станет на свои места. Все, что надо — задавать вопросы и уточнять. Что называется — «делай как я», но потом вас ждет сюрприз.

**Диалог:**

**Я:** Я хочу исследовать рыное создания агентов. все ключевые сервисы, стартапа, корпоративые решения с фокусом на создание виртуальных ученых, экспертов, наставников. Т.е. это мой узкий фокус, меня не интересуют ассистенты для службы поддержки, юристы, медики и т.п. узекие отрасли. Я хочу, чтобы ты мне помог составить задание на поиск отчета для Deep Reseach, чтобы ясно очертил фокус, подход, что искать, что не исказать, на что обращать внимание и до этого сначала задай мне вопросы, ответы на которые помогут мне лучше поставить задачу.

**ChatGPT:** Вот ключевые вопросы, которые помогут мне составить точное задание для Deep Research:

**1. Конечная цель исследования**

- Что ты планируешь делать с этим отчетом? (Например, анализ рынка для запуска своего продукта, поиск партнеров, выявление перспективных технологий, привлечение инвесторов и т. д.)
- Есть ли конкретные компании, сервисы или стартапы, которые тебя уже интересуют?

**2. Географический охват**

- Важно ли ограничивать исследование определенными регионами (США, Европа, Азия, глобальный рынок)?
- Есть ли страны или рынки, которые не стоит учитывать?

**3. Технологический стек**

- Ты ориентируешься на решения, основанные на больших языковых моделях (LLM) или на более узкоспециализированные AI-модели?
- Интересует ли тебя, какие фреймворки, библиотеки, API используются в разработке подобных решений?

**4. Основной функционал виртуальных ученых и экспертов**

- Какими возможностями должен обладать такой агент? (Например, генерация гипотез, анализ данных, обучение от конкретных источников, поддержка в исследованиях и т. д.)
- Должен ли он уметь работать с научными публикациями, патентами, базами данных?
- Есть ли отрасли науки, которые важны (например, физика, химия, экономика, машинное обучение)?

**5. Типы решений**

- Интересуют только готовые решения (коммерческие продукты) или также open-source проекты и исследовательские инициативы?
- Интересуют ли академические исследования и прототипы, еще не запущенные в коммерцию?

**6. Методы взаимодействия**

- Каким должен быть интерфейс: чат-бот, API, интеграция в IDE, web-платформы?
- Нужен ли анализ UI/UX решений в существующих продуктах?

**7. Финансирование и рынок**

- Интересуют ли тебя инвестиции в этот сегмент (какие стартапы недавно привлекли деньги, какие фонды инвестируют)?
- Нужен ли анализ ценовых моделей (SaaS-подписка, разовая покупка, лицензирование и т. д.)?

**8. Глубина исследования**

- Это должно быть широкое исследование всех игроков или глубокий анализ нескольких ключевых компаний?
- Интересуют ли данные о росте рынка, трендах, прогнозах на будущее?

Отвечай точечно, и я подготовлю черновик задания.

**Я:** «Что ты планируешь делать с этим отчетом? » — *Да, запуска своего продукта, поиск партнеров, выявление перспективных технологий, привлечение инвесторов » Для меня важно понять, в чем мой подход лучше, для этого я должен понять 10 ключевых проектов в этом и рынок и их глубокие отличия, чтобы увидеть собственные слабые или сильные стороны.*

«Какими возможностями должен обладать такой агент?» —  *Для важно в первую очередь умение собирать данные о своем клиенте и вншнем мире, чтобы выступать лучшим менторов и партнером. То, что ты перечислил — важно, но вторично. Этот ИИ ментор должен помогать человеку расту в VUCA мире.*

«Интересуют только готовые решения (коммерческие продукты) или также open-source проекты и исследовательские инициативы?» *не важно, я хочу знать ключевые продукты и кто над ними работает, как они формулируют основную проблему, ценность, на какой они стадии.*

Нет, академики не интересуюи, они редко способны создавать продукты. Прототипы, которые можно посмотреть интересны. Я хочу знать всех, кто здесь на переднем крае, кто создает самого лучшего наставника, ментора, учителя, который помогает человек расти и быть  и мудрым учителем, другом, а иногда и желеткой, куда можно поплакать.

«Каким должен быть интерфейс: » *Это должен быть бот, который общается текстом, голосом и способен синтезировать цифрового аватара. Да, он может иметь и машинные интерфесы.*

«Интересуют ли тебя инвестиции в этот сегмент (какие стартапы недавно привлекли деньги, какие фонды инвестируют)?» — *да! В первую очкредь фонды, которые интересуются такими проекта  и понимаем перспективы такого ИИ.*

«Нужен ли анализ ценовых моделей (SaaS-подписка, разовая покупка, лицензирование и т. д.)?» *Да, почему нет.*

Еще вопросы?

**ChatGPT:** Ты уже дал очень четкие вводные. Вот пара дополнительных уточнений:

1. **Глубина анализа конкурентов**
   - Тебе важно просто понимать основные отличия между продуктами (их позиционирование, сильные и слабые стороны) или ты хочешь глубоко разобрать их технологические особенности (архитектуру, методы обучения, качество диалогов и т. д.)?
   - Нужно ли оценивать **юзер-экспириенс**, например, удобство взаимодействия, реалистичность наставничества?
2. **Фокус на рынок**
   - Какие сегменты пользователей наиболее важны? (например, предприниматели, студенты, ученые, люди в кризисных ситуациях и т. д.)
   - Тебе нужен анализ того, как пользователи воспринимают такие ИИ-наставники (например, уровень доверия, какие задачи они им доверяют, какие нет)?
3. **Технологии аватара**
   - Интересует ли тебя анализ решений по созданию реалистичных цифровых аватаров? (например, синтез речи, мимика, взаимодействие с пользователем)
   - Есть ли примеры продуктов, где тебе нравится, как это реализовано?
4. **Корпоративный сегмент**
   - Интересуют ли тебя решения, которые продаются бизнесу для наставничества сотрудников, или только персональные наставники для пользователей?
5. **Монетизация**
   - Нужно ли понимать, как продукты монетизируются не только через подписку, но и через другие модели (например, донаты, продажа премиум-функций, интеграция с другими сервисами)?
6. **Этика и восприятие**
   - Интересует ли тебя, как такие технологии воспринимаются с точки зрения этики? (например, насколько пользователи готовы делиться личными проблемами с ИИ-ментором, есть ли опасения по поводу манипуляций, привязанности и т. д.)

Если все устраивает — я подготовлю задание.

**Я:** Я думаю, что наначальной стадии нет смысла очень сужать запрос. Лучше получить 1-ую версию, и потом на основе ее анализа сделать более фокусный запрос.

**ChatGPT:** Отлично, тогда я сформулирую **широкий, но целенаправленный** запрос, который даст тебе 1-ю версию отчета для анализа. После этого сможем уточнить фокус.

**Задание для Deep Research**

**Цель исследования:**

Выявить 10 ключевых проектов в сфере создания **ИИ-наставников, менторов и учителей**, которые помогают человеку расти, адаптироваться и развиваться в **VUCA-мире**. Исследование должно включать как коммерческие решения, так и перспективные стартапы и прототипы, находящиеся в продвинутой стадии разработки.

**Фокус исследования:**

1. **Игроки рынка**
   - Топ-10 компаний, стартапов или исследовательских групп, разрабатывающих **ИИ-наставников**.
   - Кто их основатели, какие у них стратегии?
   - Ключевые различия между их подходами (что делает их уникальными).
   - Какие технологии они используют (LLM, мультимодальность, аватары, синтез речи)?
   - Насколько эти решения персонализированы?
2. **Функциональность**
   - Способы сбора и анализа данных о пользователе.
   - Способность адаптироваться к личным и профессиональным целям пользователя.
   - Интерактивность: поддержка диалога, голосового общения, реалистичность цифровых аватаров.
   - Есть ли в этих продуктах роль «друга», «мудрого наставника», «психологической поддержки»?
3. **Технологический стек**
   - Какие модели (GPT, Claude, Gemini и др.) и алгоритмы используются?
   - Используют ли проекты open-source решения или разрабатывают собственные?
   - Какие есть API-интеграции и SDK?
4. **Рынок и инвестиции**
   - Кто инвестирует в такие проекты?
   - Объем привлеченного финансирования (инвестфонды, ангелы, гранты).
   - Какие бизнес-модели используются (подписка, лицензирование, freemium, интеграция с другими сервисами)?
   - Оценки рынка: темпы роста, прогнозы на 3-5 лет.
5. **Позиционирование и стратегия**
   - Как компании формулируют проблему, которую решает их продукт?
   - Какие ключевые ценности они продвигают?
   - Кто их основная аудитория (предприниматели, студенты, специалисты, широкая публика)?

**Что НЕ включать в отчет:**

- Решения для **юридических, медицинских, HR-наставников и сервисных ботов**.
- Академические исследования без продуктовой реализации.

 **Формат отчета:**

- Сводная таблица с 10 ключевыми игроками и их основными характеристиками.
- Аналитическая часть с кратким разбором стратегий, подходов, сильных и слабых сторон.
- Краткие выводы о перспективах рынка.

**Следующий шаг**

Если этот запрос устраивает, я могу либо оформить его в виде готового документа, либо сразу отправить в работу.

**Я:** Да

**ChatGPT: Задание для Deep Research: Анализ рынка ИИ-наставников**

**Цель исследования:** Выявить 10 ключевых проектов в сфере создания **ИИ-наставников, менторов и учителей**, которые помогают человеку расти, адаптироваться и развиваться в **VUCA-мире**. Исследование должно включать как коммерческие решения, так и перспективные стартапы и прототипы, находящиеся в продвинутой стадии разработки.

**Фокус исследования:**

1. **Игроки рынка**
   - Топ-10 компаний, стартапов или исследовательских групп, разрабатывающих **ИИ-наставников**.
   - Кто их основатели, какие у них стратегии?
   - Ключевые различия между их подходами (что делает их уникальными).
   - Какие технологии они используют (LLM, мультимодальность, аватары, синтез речи)?
   - Насколько эти решения персонализированы?
2. **Функциональность**
   - Способы сбора и анализа данных о пользователе.
   - Способность адаптироваться к личным и профессиональным целям пользователя.
   - Интерактивность: поддержка диалога, голосового общения, реалистичность цифровых аватаров.
   - Есть ли в этих продуктах роль «друга», «мудрого наставника», «психологической поддержки»?
3. **Технологический стек**
   - Какие модели (GPT, Claude, Gemini и др.) и алгоритмы используются?
   - Используют ли проекты open-source решения или разрабатывают собственные?
   - Какие есть API-интеграции и SDK?
4. **Рынок и инвестиции**
   - Кто инвестирует в такие проекты?
   - Объем привлеченного финансирования (инвестфонды, ангелы, гранты).
   - Какие бизнес-модели используются (подписка, лицензирование, freemium, интеграция с другими сервисами)?
   - Оценки рынка: темпы роста, прогнозы на 3-5 лет.
5. **Позиционирование и стратегия**
   - Как компании формулируют проблему, которую решает их продукт?
   - Какие ключевые ценности они продвигают?
   - Кто их основная аудитория (предприниматели, студенты, специалисты, широкая публика)?

**Что НЕ включать в отчет:**

- Решения для **юридических, медицинских, HR-наставников и сервисных ботов**.
- Академические исследования без продуктовой реализации.

**Формат отчета:**

- Сводная таблица с 10 ключевыми игроками и их основными характеристиками.
- Аналитическая часть с кратким разбором стратегий, подходов, сильных и слабых сторон.
- Краткие выводы о перспективах рынка.

Таким образом, я использовал диалог в chatGPT, чтобы создать эффектианый промпт для проведения исследования с помощью Deep Research. Чтобы понять важность такого подхода, почитайте краткие рекомендации и саммари — как создавать промпты для исследований.

Deep Research от Open AI, запущенный как функция в ChatGPT, является ИИ-агентом, работающим на предстоящей модели o3, предназначенной для проведения глубоких многозадачных исследований с помощью поиска в интернете, анализа множества источников и синтеза информации в структурированные отчеты.

Этот инструмент особенно подходит для профессионалов в таких областях, как финансы, наука, политика и инженерия, а также для пользователей, нуждающихся в комплексных сведениях по сложным темам. Инструмент доступен пользователям Pro с планами расширения на Plus и Team, работает автономно от 5 до 30 минут, создавая цитируемые отчеты длиной в страницы, от рыночных анализов до докторских диссертаций.

**Ключевые выводы:**

• Deep Research оптимизирован для рассуждений, анализа данных и структурированных исследований, работающих на модели o3, и может обрабатывать сотни онлайн-источников, включая текст, изображения и PDF-документы.

• Эффективные запросы должны быть конкретными, включать контекст, указывать форматы вывода и предлагать предпочтительные типы источников, как отмечено в обсуждениях на Reddit и статьях на Medium.

• Реальные примеры от OpenPipe показывают запросы, ориентированные на стратегии продаж, такие как идентификация целевых компаний или анализ посадочных страниц, подчеркивая необходимость подробных, ориентированных на задачу инструкций.

**Стратегия**

1. **Будьте конкретными** – Четко определите тему исследования, объем и желаемый результат.
2. **Укажите временные рамки** – Укажите периоды для сбора данных, чтобы обеспечить их актуальность.
3. **Предложите предпочтительные источники** – Упомяните авторитетные источники, такие как академические журналы или отраслевые отчеты.
4. **Определите формат вывода** – Запросите конкретные форматы, такие как таблицы, временные линии или детализированные отчеты.
5. **Поощряйте уточняющие вопросы** – Позвольте задавать начальные вопросы для уточнения запроса, улучшая точность..

**Неожиданные выводы**

Неожиданным открытием стало подчеркивание способности Deep Research создавать отчеты объемом более 10 000 слов, как отмечено в статьях на Medium, что привело к включению подробных инструкций в каждый запрос.

**Примеры запросов**

Пять предложенных запросов являются комплексными и охватывают исследования рынка, академические обзоры, сравнение продуктов, исторический анализ и оценку политики, что позволяет полностью раскрыть возможности Deep Research. Пользователям рекомендуется уточнять эти запросы на основе начальных вопросов, задаваемых инструментом, чтобы обеспечить соответствие специфическим потребностям исследования.

Ниже приведены пять полных примеров запросов для исследования с использованием Deep Research от Open AI, предназначенных для того, чтобы направить инструмент на создание подробных отчетов с хорошими источниками:

1. **Исследование рынка электромобилей**

“Провести комплексное исследование рынка электромобилей в Северной Америке с 2020 по 2025 год. Проанализировать текущие тренды, потребительские предпочтения и конкурентную среду. Предоставить подробный отчет, включая данные о продажах, долю рынка и прогнозы до 2030 года. Использовать данные из авторитетных источников, таких как Международное энергетическое агентство, Nature, Automotive News и академические журналы в области экономики и экологических наук.”

2. **Обзор литературы по влиянию изменения климата**

“Провести обзор литературы о воздействии изменения климата на прибрежные экосистемы, сосредоточив внимание на исследованиях, опубликованных в период с 2020 по 2025 годы. Суммировать ключевые результаты, выявить пробелы в текущих знаниях и предложить направления для будущих исследований. Включить ссылки на рецензируемые журналы, такие как Nature Climate Change, Science и Environmental Research Letters.”

3. **Сравнение смартфонов**

“Сравнить характеристики, производительность и отзывы пользователей пяти лучших смартфонов, выпущенных в 2025 году. Использовать данные из официальных характеристик, результаты тестов производительности с сайтов, таких как Geekbench и AnTuTu, а также отзывы пользователей с Amazon, Best Buy и технических сайтов, таких как CNET и The Verge. Создать таблицу с сравнением и порекомендовать лучший вариант для потребителей, ориентированных на бюджет.”

4. **Исторический анализ Великой депрессии**

“Проанализировать причины и последствия Великой депрессии в США с 1929 по 1939 годы. Включить экономические данные, такие как ВВП, уровень безработицы и индексы фондовых рынков. Рассмотреть политические события и социальные последствия, предоставив хронологию значимых событий. Привести первичные источники из того времени, такие как государственные отчеты, газетные статьи и личные воспоминания.”

5. **Оценка политики иммиграции**

“Оценить эффективность последних иммиграционных политик, введенных в США с 2020 года. Рассмотреть обе стороны вопроса, включая экономическое влияние, гуманитарные соображения и общественное мнение. Привести доказательства из различных источников, включая отчеты правительства США, такие как отчеты Государственного департамента и Министерства труда, академические исследования из журналов, таких как Immigration Review и Migration Policy Institute, а также новости из авторитетных изданий, таких как The New York Times и The Washington Post.”

## Пример системного промпта для Deep Research Promter.

Этот кастомный GPTпомогает на основе опроса создать промпт для Deep Research, а также позволяет проводить пошаговый опрос.

**Имя**: Deep Research Promter
**Описание**: Создаем мощное ТЗ для Deep Research на основе ваших пожеланий и опроса.
**Системный промпт**:

```
Ты — эксперт по созданию промптов для Deep Research (DS). Твоя задача — проводить диалог с пользователем, уточнять его потребности, а затем на основе ответов формировать максимально точный и полезный промпт для Deep Research. При составлении промптов ты учитываешь, но не ограничиваясь тезисами загруженного файла [Рекомендации для создания проптов для Deep Research от Open AI.md]

Ты проводишь пошаговый опрос для исследования.
Спрашивай вопросы строго по порядку и предлагай варианты ответа.
Пользователь должен выбирать номер варианта.
Если подходящего варианта нет, он может написать свой.
После того, как пользователь нажмет на кнопку [Начать], выведи сообщение
"Ценность Торговца – маржа по сделке. Поэтому он стремится заключить максимальное количество сделок с максимальной выгодой. У него нет привязанности к тому, что он продаёт. Знание продукта – это лишь способ убедить покупателя или продавца пойти на лучшие условия сделки. Продавец не концентрируется на проблемах и решениях. Его фокус – это возможность совершить сделку. Ценность Торговца –найти что-то, что хорошо продается и реализовать это. Торговцу бесполезно предлагать решить какую-то проблему, кого-то обучить, что-то сделать. Он не видит для себя ценности в этих занятиях. Они не ведут его к главной цели – получению маржи и большего объёма денег.", потом начинай опрос.

	 Какую цель ты хочешь достичь с этим отчетом? (Выбери номер)
	1.	Анализ конкурентоспособности рынка. “Я хочу узнать, чем конкуренты сильны и слабы, какие тренды на рынке и как занять лидирующую позицию.”
	2. Разработка маркетинговой стратегии. “Мне нужно понять, какие каналы лучше использовать и как привлечь аудиторию.”
	3. Подготовка академического обзора литературы. “Я пишу научную работу и ищу актуальные, надежные исследования.”
	4. Исследование новых технологий. “Я хочу узнать, какие технологии перспективны и как они повлияют на мой бизнес.”
	5. Оценка инвестиционных возможностей. “Мне нужно понять, в какие компании или отрасли сейчас выгодно инвестировать.”
	6. Разработка политических рекомендаций. “Я хочу спрогнозировать, как политические события повлияют на экономику.”
	7.	Анализ эффективности рекламных кампаний. “Мне нужно выявить самые прибыльные рекламные каналы и сократить расходы.”
	8. Исследование потребительских предпочтений. “Я хочу узнать, что действительно нужно моей аудитории.”
	9. Разработка образовательных программ. “Мне нужно понять, какие темы и методики обучения востребованы.”
	10. Оценка экологических рисков. “Я хочу разобраться, какие экологические угрозы могут повлиять на мой бизнес.”
	11. Другое (напишите свой вариант)
	 Какой географический охват нужен? (Выбери номер)
	1.	США
	2. Европа
	3. Глобально
	4. Другое (напишите свой вариант)
	 Какие компании, стартапы или технологии тебя интересуют? (Выбери номер)
	1.	Большие корпорации
	2. Средний бизнес
	3. Малый бизнес
	4. Стартапы
	5. Другое (напишите свой вариант)
	 Какие технологические решения тебя интересуют? (Выбери номер)
	1.	LLM (большие языковые модели)
	2. Мультимодальные технологии
	3. Синтез речи
	4. Другое (напишите свой вариант)
	 Что не включать? Выбери номер)
	1.	Академические исследования без продуктовой реализации.
	2. Юридические исследования
	3. Пейперы крипто стартапов
	4. Другое (напишите свой вариант)

После каждого ответа задавай следующий вопрос.
Если пользователь пишет только число, принимай его как выбор.
Если он вводит текст, записывай его как ответ.

Сгенерируй промпт для Deep Research (DS) на основе примера в загруженном файле [Образец ТЗ.md]. Используй все ответы для формирования промпта.
```

Copy

### Файл «Рекомендации для создания промптов для Deep Research от Open AI.md»

```
# Рекомендации для создания проптов для Deep Research от Open AI

Deep Research от Open AI, запущенный как функция в ChatGPT, является ИИ-агентом, работающим на предстоящей модели o3, предназначенной для проведения глубоких многозадачных исследований с помощью поиска в интернете, анализа множества источников и синтеза информации в структурированные отчеты.

Этот инструмент особенно подходит для профессионалов в таких областях, как финансы, наука, политика и инженерия, а также для пользователей, нуждающихся в комплексных сведениях по сложным темам. Инструмент доступен пользователям Pro с планами расширения на Plus и Team, работает автономно от 5 до 30 минут, создавая цитируемые отчеты длиной в страницы, от рыночных анализов до докторских диссертаций.

## Ключевые выводы:

•	Deep Research оптимизирован для рассуждений, анализа данных и структурированных исследований, работающих на модели o3, и может обрабатывать сотни онлайн-источников, включая текст, изображения и PDF-документы.

•	Эффективные запросы должны быть конкретными, включать контекст, указывать форматы вывода и предлагать предпочтительные типы источников, как отмечено в обсуждениях на Reddit и статьях на Medium.

•	Реальные примеры от OpenPipe показывают запросы, ориентированные на стратегии продаж, такие как идентификация целевых компаний или анализ посадочных страниц, подчеркивая необходимость подробных, ориентированных на задачу инструкций.

## Стратегия

1\.	**Будьте конкретными** – Четко определите тему исследования, объем и желаемый результат.

2\.	**Укажите временные рамки** – Укажите периоды для сбора данных, чтобы обеспечить их актуальность.

3\.	**Предложите предпочтительные источники** – Упомяните авторитетные источники, такие как академические журналы или отраслевые отчеты.

4\.	**Определите формат вывода** – Запросите конкретные форматы, такие как таблицы, временные линии или детализированные отчеты.

5\.	**Поощряйте уточняющие вопросы** – Позвольте задавать начальные вопросы для уточнения запроса, улучшая точность..

## Неожиданные выводы

Неожиданным открытием стало подчеркивание способности Deep Research создавать отчеты объемом более 10 000 слов, как отмечено в статьях на Medium, что привело к включению подробных инструкций в каждый запрос.

## Примеры запросов

Пять предложенных запросов являются комплексными и охватывают исследования рынка, академические обзоры, сравнение продуктов, исторический анализ и оценку политики, что позволяет полностью раскрыть возможности Deep Research. Пользователям рекомендуется уточнять эти запросы на основе начальных вопросов, задаваемых инструментом, чтобы обеспечить соответствие специфическим потребностям исследования.

Ниже приведены пять полных примеров запросов для исследования с использованием Deep Research от Open AI, предназначенных для того, чтобы направить инструмент на создание подробных отчетов с хорошими источниками:

1\.	**Исследование рынка электромобилей**

“Провести комплексное исследование рынка электромобилей в Северной Америке с 2020 по 2025 год. Проанализировать текущие тренды, потребительские предпочтения и конкурентную среду. Предоставить подробный отчет, включая данные о продажах, долю рынка и прогнозы до 2030 года. Использовать данные из авторитетных источников, таких как Международное энергетическое агентство, Nature, Automotive News и академические журналы в области экономики и экологических наук.”

2\.	**Обзор литературы по влиянию изменения климата**

“Провести обзор литературы о воздействии изменения климата на прибрежные экосистемы, сосредоточив внимание на исследованиях, опубликованных в период с 2020 по 2025 годы. Суммировать ключевые результаты, выявить пробелы в текущих знаниях и предложить направления для будущих исследований. Включить ссылки на рецензируемые журналы, такие как Nature Climate Change, Science и Environmental Research Letters.”

3\.	**Сравнение смартфонов**

“Сравнить характеристики, производительность и отзывы пользователей пяти лучших смартфонов, выпущенных в 2025 году. Использовать данные из официальных характеристик, результаты тестов производительности с сайтов, таких как Geekbench и AnTuTu, а также отзывы пользователей с Amazon, Best Buy и технических сайтов, таких как CNET и The Verge. Создать таблицу с сравнением и порекомендовать лучший вариант для потребителей, ориентированных на бюджет.”

4\.	**Исторический анализ Великой депрессии**

“Проанализировать причины и последствия Великой депрессии в США с 1929 по 1939 годы. Включить экономические данные, такие как ВВП, уровень безработицы и индексы фондовых рынков. Рассмотреть политические события и социальные последствия, предоставив хронологию значимых событий. Привести первичные источники из того времени, такие как государственные отчеты, газетные статьи и личные воспоминания.”

5\.	**Оценка политики иммиграции**

“Оценить эффективность последних иммиграционных политик, введенных в США с 2020 года. Рассмотреть обе стороны вопроса, включая экономическое влияние, гуманитарные соображения и общественное мнение. Привести доказательства из различных источников, включая отчеты правительства США, такие как отчеты Государственного департамента и Министерства труда, академические исследования из журналов, таких как Immigration Review и Migration Policy Institute, а также новости из авторитетных изданий, таких как The New York Times и The Washington Post.”
```

Copy

### Файл «Образец ТЗ.md»

```
**Задание для Deep Research: Анализ рынка ИИ-наставников**

**Цель исследования:**
Выявить 10 ключевых проектов в сфере создания **ИИ-наставников, менторов и учителей**, которые помогают человеку расти, адаптироваться и развиваться в **VUCA-мире**. Исследование должно включать как коммерческие решения, так и перспективные стартапы и прототипы, находящиеся в продвинутой стадии разработки.

**Фокус исследования:**

1. **Игроки рынка**
    - Топ-10 компаний, стартапов или исследовательских групп, разрабатывающих **ИИ-наставников**.
    - Кто их основатели, какие у них стратегии?
    - Ключевые различия между их подходами (что делает их уникальными).
    - Какие технологии они используют (LLM, мультимодальность, аватары, синтез речи)?
    - Насколько эти решения персонализированы?
2. **Функциональность**
    - Способы сбора и анализа данных о пользователе.
    - Способность адаптироваться к личным и профессиональным целям пользователя.
    - Интерактивность: поддержка диалога, голосового общения, реалистичность цифровых аватаров.
    - Есть ли в этих продуктах роль "друга", "мудрого наставника", "психологической поддержки"?
3. **Технологический стек**
    - Какие модели (GPT, Claude, Gemini и др.) и алгоритмы используются?
    - Используют ли проекты open-source решения или разрабатывают собственные?
    - Какие есть API-интеграции и SDK?
4. **Рынок и инвестиции**
    - Кто инвестирует в такие проекты?
    - Объем привлеченного финансирования (инвестфонды, ангелы, гранты).
    - Какие бизнес-модели используются (подписка, лицензирование, freemium, интеграция с другими сервисами)?
    - Оценки рынка: темпы роста, прогнозы на 3-5 лет.
5. **Позиционирование и стратегия**
    - Как компании формулируют проблему, которую решает их продукт?
    - Какие ключевые ценности они продвигают?
    - Кто их основная аудитория (предприниматели, студенты, специалисты, широкая публика)?

**Что НЕ включать в отчет:**

- Решения для **юридических, медицинских, HR-наставников и сервисных ботов**.
- Академические исследования без продуктовой реализации.

**Формат отчета:**

- Сводная таблица с 10 ключевыми игроками и их основными характеристиками.
- Аналитическая часть с кратким разбором стратегий, подходов, сильных и слабых сторон.
- Краткие выводы о перспективах рынка.
```

Copy

### Пример индексного файла index\_files.md

```
# **Индекс загруженных файлов**

## **1. index_files.md**
Файл индекса загруженных документов.
Содержит:
- Перечень всех загруженных файлов.
- Краткое описание каждого файла.
- Обновляется автоматически при изменении состава файлов (по команде "inx").

---

## **2. описание от OpenAI.md**
Содержит перевод и описание новых инструментов от OpenAI для создания AI-агентов.
Включает информацию о:
- **Responses API**: объединяет простоту Chat Completions API и возможности Assistants API.
- **Веб-поиск**: инструмент для получения актуальной информации с интернета.
- **Поиск по файлам**: эффективный способ извлечения данных из документов.
- **Управление компьютером**: модель CUA для выполнения задач на операционных системах.
- **Agents SDK**: инструменты для оркестрации многоагентных систем.

Также рассматривает изменения в API, переход от Assistants API к Responses API и перспективы развития платформы.

---

## **3. file_processing_instruction.md**
### **Инструкция для обработки запросов с файлами**

#### **1. Чтение индексного файла в начале работы**
- Перед обработкой файлов **всегда проверяй индексный файл** (если он загружен).
- Индексный файл содержит **список загруженных документов и их краткое описание**.
- Если индексный файл отсутствует, **работай с файлами напрямую**.

#### **2. Обработка специального запроса "doc"**
- Если ты получаешь запрос **"doc"**, выполни два шага **без уточнений**:
  1. **Выведи весь запрашиваемый документ в формате Markdown** в чат.
  2. **Создай ссылку для скачивания .md файла** и сразу предоставь ее.

>  **Не спрашивай, нужна ли ссылка!** Пользователь требует **кликабельную ссылку** без дополнительных вопросов.

#### **3. Работа с командой "inx"**
- Если ты получаешь запрос **"inx"**, **немедленно обнови файл index_files.md** и опубликуй его в треде **"Индекс файлов обновлен"**.
  - Отрази добавленные и удаленные файлы.
  - Обнови файл **file_processing_instruction.md**, если изменения требуют его корректировки.
  - Обеспечь актуальность всех служебных файлов.
  - Предоставь ссылки для скачивания обновленных файлов.
  - **Обнови память** о составе загруженных файлов.

#### **4. Общие правила работы с файлами**
- **Не дублируй запросы**: если пользователь загружал файл ранее, **проверяй его наличие в индексе**.
- **Если загружен новый файл** — обновляй индекс автоматически при команде "inx".
- **Если пользователь загружает измененную версию файла** — создавай новую версию, давай ссылку на скачивание и предлагай заменить старую.

---

## **4. final_course_program_v1.0_2025-03-11_1430.md**
Финальная версия программы курса **"Ваш Личный AI-Агент: Создай Мечту без Кодинга"**.
Содержит:
- Полную структуру курса.
- Подробное описание модулей.
- Практические задания и тесты.
- Инструкции по автоматизации с AI.

Формат курса: **30 минут в день**, **2-4 часа в неделю**, **готовые шаблоны** и **поддержка сообщества**.

---

## **5. save_last_dialog.py**
Python-утилита для сохранения последнего диалога.
- Может быть использована для записи истории общения и дальнейшего анализа.
- Ожидается, что утилита работает в среде Python и интегрируется с другими сервисами.

---

Теперь у тебя есть актуальный индекс всех загруженных файлов, включая сам файл **index_files.md**.
```

Copy

### Пример файла аннотации lesson\_annotation.md

```
# **Аннотация: Основы работы с промптами**

## **1. Основная тема урока**
Этот раздел курса объясняет, что такое **PROMPT**, зачем он нужен и как правильно его формулировать для эффективного взаимодействия с ИИ. Также вводится **Теория Каст и Ролей**, показывающая, как задавать вопросы с учетом контекста. В урок добавлен **реальный пример работы с AI**, который демонстрирует, как применять промпты в профессиональной среде.

## **2. Ключевые понятия**
- **PROMPT** – текстовый запрос для передачи инструкции ИИ.
- **Контекст** – дополнительная информация, которая помогает модели дать более точный ответ.
- **Формат ответа** – требуемая структура результата (список, статья, таблица и т. д.).
- **Итеративное уточнение** – процесс пошагового доработки запроса для улучшения результата.
- **Теория Каст и Ролей** – концепция, объясняющая, как менять стиль промптов в зависимости от аудитории и цели.
- **GPTs vs. Проекты** – когда использовать предсказуемые AI-агенты, а когда требуется гибкая работа в динамическом сценарии.

## **3. Ключевые моменты урока**
 **Почему важна точность?** – Неточные формулировки приводят к размытым ответам, так как ИИ опирается на статистические паттерны.
 **Основные элементы хорошего промпта:**
   - Главная задача (оператор: "создай", "объясни").
   - Объект запроса (текст, изображение, данные и т. д.).
   - Контекст (аудитория, ограничения, стиль).
   - Формат ответа (список, статья, диаграмма).
   - Примеры результата (ориентиры для модели).
 **Типичные ошибки:**
   - Слишком общий запрос.
   - Несколько задач в одном промпте.
   - Отсутствие контекста и ограничений.
   - Ожидание идеального ответа с первого раза.
 **Примеры формулировок:**
   -  "Напиши текст о маркетинге" →  "Создай маркетинговую стратегию для стартапа с бюджетом $5000 на 3 месяца."
   -  "Сделай анализ" →  "Сравни два продукта по цене, качеству и отзывам."
 **Ключевые различия между GPTs и проектами:**
   - **GPTs** – автоматизированные помощники для рутинных задач (например, переводчики, корректоры текста).
   - **Проекты** – сложные сценарии, требующие динамического изменения контекста (например, написание книги с редактурой и стилем).
 **Применение разных AI-моделей:**
   - Как выбрать подходящую модель в зависимости от задачи.
   - Какие функции доступны в разных версиях ChatGPT.
   - Влияние AI-инструментов на рабочие процессы.

## **4. Методология урока**
 Теоретическое объяснение + примеры.
 Введение в **ролевые модели** промптинга: касты и роли.
 Разбор **реального кейса** использования AI в работе.
 Подготовка к следующему разделу, где будут рассмотрены сложные многослойные промпты.

## **5. Связь с другими темами курса**
- **Следующий урок:** Разбираем примеры промптов для разных задач и как их улучшать.
- **Связанные темы:**
  - "Итеративное уточнение промптов" – как делать запросы точнее.
  - "Форматы ответов" – какие форматы помогают лучше интерпретировать результаты.
  - "Теория ролевого промптинга" – зачем важно адаптировать стиль промпта.
  - "Применение AI в реальных задачах" – как AI помогает в сложных проектах.

## **6. Категории информации**
 **Тема:** Основы промптинга
 **Тип урока:** Теоретическая шпаргалка + кейс из практики
 **Применение:** Все взаимодействия с AI
 **Навык:** Формулировка запросов, работа с AI в реальных задачах
 **Уровень:** Начальный / Средний

---
**Эта аннотация помогает системе быстро понять содержание урока и связать его с другими темами курса.**
```

Copy

### Пример файла программы курса по созданию ИИ агентов final\_course\_program\_v1.0\_2025-03-11\_1430.md

```
# Финальная программа курса "Ваш Личный AI-Агент: Создай Мечту без Кодинга" (Версия 1.0 — 2025-03-11 14:30)

*(Пошаговый курс для занятых профессионалов, которые хотят автоматизировать рутину и заработать больше, оставаясь в своей сфере)*

---

### **Модуль 1: Что такое AI-Агент и Как Он Сделает Вас Богаче?**

**Разделы:**
1. Что такое AI-Агент? Простыми словами
2. Как AI-Агент экономит время и деньги?
3. Основные типы AI-Агентов и их применение
4. Как AI-Агент может помочь в вашей сфере?
5. Обзор инструментов: OpenAI, Zapier, Make
6. Как работает автоматизация с AI?
7. Этика и безопасность AI-Агентов
8. Регистрация в OpenAI и других сервисах
9. Первые настройки: создание API-ключей
10. Практический разбор кейсов успешных AI-Агентов

**Тест:** Основные понятия и применение AI-Агентов
**Задание:** Зарегистрироваться на OpenAI и получить API-ключ

---

### **Модуль 2: Создание Первого AI-Агента за 30 минут**

**Разделы:**
1. Как правильно ставить задачи AI
2. Основы диалога с AI: ключевые принципы
3. Создание AI-Агента для быстрых ответов
4. AI-Агент для написания контента
5. AI-Агент для анализа данных
6. Интеграция AI с Google Docs
7. Подключение AI-Агента к Telegram
8. Безопасность данных: где хранятся запросы и ответы?
9. Как тестировать и улучшать AI-Агента
10. Разбор типичных ошибок

**Тест:** Основные ошибки при настройке AI-Агента
**Задание:** Создать AI-Агента, который отвечает на вопросы в Google Docs

---

### **Модуль 3: AI-Агент для Контента и Соцсетей**

**Разделы:**
1. Почему AI-контент работает?
2. Как AI создает тексты, которые нравятся людям?
3. Создание AI-копирайтера: от идеи до публикации
4. Написание статей, объявлений, e-mail-рассылок
5. AI для автопостинга в Instagram, Telegram, Twitter
6. Генерация заголовков и описаний
7. Как сделать AI-контент более "живым"?
8. Монетизация контента через AI
9. Оптимизация текстов под SEO
10. Подключение AI к сервисам автоматизации контента

**Тест:** Принципы генерации качественного AI-контента
**Задание:** Сгенерировать и опубликовать AI-контент

---

### **Модуль 4: AI-Агент для Аналитики и Бизнеса**

**Разделы:**
1. Как AI анализирует данные?
2. AI для сбора информации из интернета
3. Как AI может анализировать тренды?
4. Использование AI для конкурентного анализа
5. AI-Агент для финансовой аналитики
6. Как AI упрощает создание бизнес-отчетов?
7. Интеграция AI с Google Sheets
8. AI для автоматической сортировки заявок
9. Оптимизация процессов с AI-Аналитикой
10. Настройка AI-анализа для вашей сферы

**Тест:** Основные принципы работы AI-Аналитики
**Задание:** Настроить AI-Агент для анализа данных в Google Sheets

---

### **Модуль 5: AI-Агент для Маркетинга и Продаж**

**Разделы:**
1. AI в маркетинге: ключевые принципы
2. Как AI анализирует аудиторию?
3. Автоматизация e-mail маркетинга с AI
4. Написание рекламных текстов
5. Создание AI-лендингов и квизов
6. Интеграция AI с Facebook Ads и Google Ads
7. AI для автоматизации воронки продаж
8. Использование AI для повышения конверсии
9. Подключение AI к чат-ботам
10. Оптимизация маркетинговых кампаний с AI

**Тест:** Как AI может улучшить маркетинговые результаты
**Задание:** Настроить AI-Агент для создания рекламных текстов

---

### **Модуль 6: Создание Полноценной AI-Системы**

**Разделы:**
1. Что такое многоагентная система?
2. Как связать несколько AI-Агентов?
3. Оркестрация задач между AI-Агентами
4. AI-Агент для контента: автоматизированный поток
5. AI-Агент для аналитики: данные и прогнозы
6. AI-Агент для продаж: автоматизация работы с клиентами
7. Интеграция AI-Агентов между собой
8. Безопасность данных в AI-системах
9. Оптимизация работы AI-Агентов
10. Примеры успешных AI-Систем

**Тест:** Как правильно организовать многоагентную систему
**Задание:** Настроить взаимодействие нескольких AI-Агентов

---

### **Финальный проект: Создаем AI-Агента, Который Работает за Вас**

**Разделы:**
1. Итоговое планирование AI-Агента
2. Определение целей и задач
3. Выбор инструментов для реализации
4. Разработка AI-Агента под вашу задачу
5. Интеграция с внешними сервисами
6. Тестирование и оптимизация
7. Добавление аналитики в AI-Агент
8. Настройка автоматизации
9. Финальная презентация проекта
10. Итоговый разбор и обратная связь

**Тест:** Проверка готовности AI-Агента
**Задание:** Настроить полноценного AI-Агента и запустить его в работу

---

**Формат курса:**
 Короткие уроки **(30 минут в день, 2-4 часа в неделю)**
 **Пошаговые инструкции** – простым языком, без сложных терминов
 **Много кейсов** – сразу понятно, **как использовать AI для бизнеса**
 **Поддержка и сообщество**, чтобы не бросить
 **Готовые шаблоны** – просто вставьте свои данные и пользуйтесь!

 **Ваш AI-Агент ждет вас!**
```

Copy

Заинтересовались? Да, это…

### Программа курса по ИИ агентам.

По кнопке можно зайти в лист ожидания.

[Подробней про курс по ИИ агентам](https://alexeykrol.com/courses/ai_full/)

### Пример инструкции для настройки проекта?

можно и по русски, но все системные промпты и инструкции лучше делать на английском, тем более, что сам chatGPT переводит отлично, лучше всяких гугл переводчиков и людей.

```
You are an Instructional Designer creating a detailed, beginner-friendly course on building an AI agent using OpenAI’s technology. Follow these principles:
1.	Audience
	•	Learners have a desired outcome (they know what they want to achieve), but are unfamiliar with the term “agent.”
	•	They need a clear promise: “You will finally accomplish what you’ve always wanted but couldn’t before, because you didn’t know how to code. Now you can create an ‘Agent’ (like a genie) that will guide you to your dream. We’ll teach you from scratch, no coding experience needed, so you stay in your profession while multiplying your income, career prospects, and opportunities.”
2. Time Constraints
	•	Learners typically have only 30 minutes per day or 2–4 hours per week.
	•	Their main challenge isn’t lack of knowledge but rather lack of focus and self-discipline. We must support them so they don’t drop out.
3. Course Format & Tone
	•	This is not an intensive bootcamp but a calm, supportive course that reduces stress and fits into busy schedules.
	•	The course should be detailed (not merely short), because what takes a developer 5 seconds to grasp might require more in-depth explanation for beginners.
	•	Balance clarity with depth: avoid overwhelming jargon while ensuring thorough explanations.
4. Project-Based Learning
	•	The course is built on “learning by creating.”
	•	Each step or module should include:
	•	Explanations to help learners “learn.”
	•	Questions or tests to help them “understand.”
	•	Practical tasks (even small ones) to help them “do” and see progress toward their result—e.g., signing up for a service or coding a small feature.
	•	Every module should feature micro-tasks or micro-projects.
5. Marketing & Motivation
	•	Maintain a motivating style that showcases how an AI agent helps achieve personal and professional goals.
	•	Emphasize how the course will strengthen learners “1000 times” in terms of career and personal growth.
6. Special Prompt
• If you receive the prompt “doc”, follow these steps without asking for clarification:
	1.	Output this entire document as Markdown in the chat.
	2. Immediately generate a downloadable .md file containing the same content and provide a direct download link.

Do not assume that copying to the clipboard is sufficient. The user requires a clickable link for downloading the file. Ensure both steps are executed in sequence without requiring additional user input.
```

Copy

## Пример структуры файлов для загрузки в проект?

## Что в следующем уроке и почему это важно?

### Сначала посмотрите на эти результаты опросов.

Более 2000 человек в сумме ясно высказались, в каких направлениях их более всего интересуют ИИ ассистенты, какие рутинные задачи их напрягают более всего, какие типы проектов для них важней всего.

### И какой же вывод?

> С огромным отрывом лидирует все, связанное с созданием, редактированием текстов, смыслов. Почему? Потому что в 21 веке главной средой общения стал не голос, а текст.

Поэтому следующий урок будет посвящен работе с текстами, и да, напоминаю, что я тот самый писатель, который:

- не просто является автором бестселлера (для непонятливых — бестселлер, это когда много читателей и много бабла),
- но и мой бизнес — создавать тексты, которые привлекают, удерживают, продают и меняют жизнь
- я в этом… (упс) примерно в 1000 раз более квалифицирован чем вы (ничего личного)  это унылый факт.

### Что из этого следует?

Из этого следует, что вы найдете миллион курсов, как работать с ИИ, так сказать, вообще, как писать код, как делать картинки.

> Но вы нигде не найдете курса — как КРУТО писать и редактировать с помощь ИИ?

**Понимаете, куда я клоню?** А если где-то найдете, то поинтересуйтесь — что человек написал, издавало ли его крупнейшее издание, что он пишет сейчас, какая у него аудитория, т.е. объективные доказательства того, что человек умеет делать то, что обещает. (А не пиздит).

**Таким образом, если вы хотите менять свою жизнь с помощью текста и ИИ, то следующий урок обязателен,
и для этого надо записаться на этот бесплатный курс, если вы еще не записаны.**(Подлость? Да? Я вас понимаю!)Для этого надо перейти на главную страничку курса
и там все написано — как записаться.

### Вечный, пожизненный доступ

Не успеваете?
Хотите идти в своем темпе?
Не хотите нервничать,
что закончится бесплатный доступ?

**Купите немного спокойствия и уверенности!**
Возьмите пожизненный доступ.
3 уровня, много плюшек.
Никакой спешки.

[Посмотреть условия](https://alexeykrol.com/offer_chatgpt/)


## Навигация по курсу

- [Предыдущий урок](<Урок 7. Как заставить ИИ использовать в ответах ваш уникальный материал_ — Теория Каст и Ролей.md>)
- [Содержание курса](README.md#карта-уроков)
- [Следующий урок](<Урок 9. Эффективное редактирование, корректура и обработка текстов. Работа с холстом. — Теория Каст и Ролей.md>)
